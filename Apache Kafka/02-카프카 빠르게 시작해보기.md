#### 해당 TIL은 **최원영님의 아파치 카프카 애플리케이션 프로그래밍 with 자바** 책으로 공부한 내용을 정리한 글입니다.
<img src="images/아파치 카프카 애플리케이션 프로그래밍 with 자바.jpeg" alt="">

## 실습용 카프카 브로커 설치
AWS EC2 인스턴스를 생성하고 해당 인스턴스에 카프카를 구축한다.
<img src="images/EC2 생성.png">
Amazon Machine Image는 Amazon Linux 2를 선택한다.
Amazon Linux 2는 Amazon에서 직접 만든 템플릿으로 EC2에 최적화되어 있다.

### AWS EC2 아키텍처 유형
<img src="images/EC2 아키텍처 유형.png">
아키텍처 유형에는 x86과 Arm 아키텍처 두 가지가 존재하는데 Intel 칩 기반 x86을 선택한다.

### AWS EC2 인스턴스 유형
<img src="images/EC2 인스턴스 유형.png">
EC2 인스턴스 유형은 프리티어로 사용할 수 있는 t2.micro로 설정한다.

### AWS EC2 인바운드 규칙
<img src="images/EC2 인바운드 규칙.png">
- 카프카 브로커의 기본 포트 : 9092
- 주키퍼의 기본 포트 : 2181

카프카 브로커와 주키퍼 접근을 위해 두 포트에 대한 인바운드 규칙을 추가한다.

### ssh 접속
<img src="images/EC2 ssh 접속.png">
EC2 생성 시 만든 pem키를 사용해 로컬에서 EC2 인스턴스로 ssh 접속한다.

### 인스턴스에 자바 설치
카프카 브로커를 실행하기 위해서는 JDK가 필요하다.
카프카 브로커는 스칼라와 자바로 작성되어 JVM 환경 위에서 실행되기 때문이다.
```shell
$ sudo yum install -y java-1.8.0-openjdk.devel.x86_64
```
<img src="images/Java 버전.png">

### 주키퍼, 카프카 브로커 실행
```shell
$ wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz
```
<img src="images/카프카 바이너리 패키지 다운로드.png">
카프카 브로커를 실행하기 위해 카프카 바이너리 패키지를 다운로드한다.

다운로드 후 압축파일을 푼다.
```shell
$ tar xvf kafka_2.12-2.5.0.tgz
```

### 카프카 브로커 힙 메모리 설정
카프카 패키지의 힙 메모리는 카프카 브로커가 1G, 주키퍼가 512MB로 기본 설정되어 있다.


따라서, 생성한 EC2 인스턴스(t2.micro)는 1G의 메모리를 가지고 있기 때문에 기본 설정 그대로 실행하게 된다면 메모리가 부족하여 실행되지 않는다.

이를 해결하기 위해 export 명령어를 사용해 힙 메모리 사이즈를 미리 환경변수로 지정한다.
```shell
$ export KAFKA_HEAP_OPTS="-Xmx400m -Xmx400m"
```

### 주키퍼 실행
주키퍼는 카프카 바이너리가 포함된 폴더에 같이 존재한다.

주키퍼는 분산 코디네이션 서비스를 제공하며 카프카를 실행하는 데에 필요한 필수 애플리케이션이다.

주키퍼를 상용환경에서 안전하게 운영하기 위해서는 3대 이상의 서버로 구성하여 사용해야 하지만 본 실습에서는 1대로 실행한다.

1대만 실행하는 주키퍼를 `Quick-and-dirty single-node`라고 한다.

```shell
$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```

### 카프카 브로커 실행
```shell
$ bin/kafka-server-start.sh -daemon config/server.properties
```
카프카가 정상적으로 연결되지 않거나 데이터가 전송되지 않거나 하는 등의 이슈가 발생할 경우 모드 카프카 브로커에 로그가 남기 때문에 이슈가 발생하면 로그를 최우선으로 확인해야 한다.

## 카프카 커맨드 라인 툴

카프카 커맨드 라인 툴은 카프카를 운영할 때 가장 많이 접하는 도구이다.

커맨드 라인 툴을 이용해 카프카 브로커 운영에 필요한 다양한 명령을 내릴 수 있다.

카프카 클라이언트 애플리케이션을 운영할 때는 카프카 클러스터와 연동하여 데이터를 주고받는 것도 중요하지만 토픽이나 파티션 개수 변경과 같은 명령을 실행해야 하는 경우도 자주 발생한다.

따라서, 카프카 커맨드 라인 툴과 각 툴별 옵션에 대해 알고 있어야 한다.

### kafka-topics.sh

토픽이란 카프카에서 데이터를 구분하는 가장 기본적인 개념이다.

마치 RDBMS에서 사용하는 테이블과 유사하다고 볼 수 있다.

카프카 클러스터에 토픽은 여러 개 존재할 수 있고, 토픽에는 파티션이 존재한다.

파티션은 카프카에서 토픽을 구성하는 데에 아주 중요한 요소이며 1개부터 시작한다.

파티션은 한 번에 처리할 수 있는 데이터양을 늘릴 수 있고 토픽 내부에서도 파티션을 통해 데이터의 종류를 나누어 처리할 수 있기 때문이다.

토픽을 생성하는 2가지 방법

토픽을 생성하는 상황은 크게 2가지가 있다.

- 카프카 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대해 데이터를 요청할 때
- 커맨드 라인 툴로 명시적으로 토픽을 생성

토픽을 효과적으로 유지보수하기 위해서는 토픽을 명시적으로 생성하는 것이 좋다.

- 토픽마다 처리되어야 하는 데이터의 특성이 다르기 때문

### 토픽 생성

```bash
$ bin/kafka-topics.sh \
	--create \
	--bootstrap-server my-kafka:9092 \
	--topic hello.kafka \
```

---

- `--create` 옵션으로 토픽을 생성
- `--bootstrap-server` 에는 토픽을 생성할 카프카 클러스터를 구성하는 브로커들의 ip와 port를 기입
- `--topic` 에서 토픽 이름을 작성. 되도록 자세하게 적는 것을 추천 (수많은 토픽이 만들어지는데 토픽 이름이 불명확하다면 유지보수가 어려워짐)

### 파티션 개수, 복제 개수, 토픽 데이터 유지 기간 옵션들을 지정하여 토픽 생성 시

```bash
$ bin/kafka-topics.sh \
	--create \
	--bootstrap-server my-kafka:9092 \
	--partitions 3 \
	--replication-factor 1 \
	--config retention.ms=172800000 \
	--topic hello.kafka.2
```

- `--partitions` 는 파티션 개수를 지정한다. 이 옵션을 사용하지 않으면 카프카 브로커 설정파일(config/server.properties)에 있는 `num.partitions` 옵션값을 따라 생성한다.
- `--replication-factor` 에는 토픽의 파티션을 복제할 복제 개수를 적는다.
    - 1은 복제를 하지 않고 사용한다는 의미
    - 2는 1개의 복제본을 사용하겠다는 의미
    - 상용 환경에서는 2 또는 3을 사용
- `--config` 를 통해 [kafka-topic.sh](http://kafka-topic.sh) 명령에 포함되지 않은 추가적인 설정 가능
    - [retention.ms](http://retention.ms)는 토픽의 데이터를 유지하는 기간 (172800000ms == 2일)


### 토픽 리스트 조회

```bash
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
```

### 토픽 상세 조회

```bash
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2
```

<img src="images/카프카 토픽 상세 조회.png">

이미 생성된 토픽의 상태를 `--describe` 옵션을 사용하여 확인할 수 있다.

- 파티션 개수
- 복제된 파티션이 위치한 브로커 번호
- 기타 토픽을 구성하는 설정들
- 토픽을 가진 파티션의 리더가 현재 어느 브로커에 존재하는지 확인 가능

카프카 클러스터의 성능이 생각보다 좋지 않다면 토픽 상세 조회 명령을 통해 토픽의 리퍼 파티션 쏠림 현상을 확인하는 것도 좋은 방법이다.

- 토픽의 리더 파티션이 일부 브로커에 몰려있을 수 있기 때문!

### 토픽 옵션 수정

토픽에 설정된 옵션을 변경하기 위해서는 [kafka-topics.sh](http://kafka-topics.sh) 또는 [kafka-configs.sh](http://kafka-configs.sh) 두 개를 사용해야 한다.

- 파티션 개수 변경 시 kafka-topics.sh를 사용
- 토픽 삭제 정책인 리텐션 기간을 변경 시 kafka-configs.sh를 사용

이와 같이 토픽 설정 옵션이 파편화된 이유는 정보를 관리하는 일부 로직이 다른 명령어로 넘어갔기 때문이다.

토픽 옵션 중 다이나믹 토픽 옵션이라고 정의되는 일부 옵션들(log.segment.bytes, [log.retention.ms](http://log.retention.ms) 등)은 kafka-configs.sh를 통해 수정할 수 있다.

```bash
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka \
	--alter \
	--partitions 4
```

<img src="images/카프카 토픽 파티션 변경.png">

```bash
$ bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
	--entity-type topics \
	--entity-name hello.kafka \
	--alter --add-config retention.ms=86400000
```

<img src="images/카프카 토픽 리텐션 기간 변경.png">

### kafka-console-producer.sh

[kafka-console-producer.sh](http://kafka-console-producer.sh) 명령어는 생성된 토픽에 데이터를 넣을 수 있다.

토픽에 넣는 데이터는 **레코드라고 부르며 메시지 키와 메시지 값으로 이루어져 있다.**

```bash
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka
```

`[kafka-console-producer.sh](http://kafka-console-producer.sh)` 로 전송되는 레코드 값은 UTF-8을 기반으로 Byte로 변환되고 ByteArraySerializer로만 직렬화된다.

- String 타입 외에는 전송 불가
- 다른 타입으로 직렬화하여 데이터 전송을 원한다면 카프카 프로듀서 애플리케이션을 직접 개발해야 함

```bash
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	--topic hello.kafka \
	--property "parse.key=true" \
	--property "key.separator=:"
```

<img src="images/카프카 콘솔 프로듀서 키 밸류.png">

- `--property "parse.key=true"`   옵션을 사용하면 레코드를 저농할 때 메시지 키를 추가할 수 있다.
- `--property "key.separator=:"`  옵션을 사용하면 메시지 키와 값을 구분하는 구분자를 선언한다. 기본 구분자는 Tab(\t)이다.

메시지 키와 메시지 값을 함께 전송한 레코드는 토픽의 파티션이 저장된다.

메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위(레코드 전송 묶음)로 라운드 로빈으로 전송한다.

메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당된다.

메시지 키가 동일한 경우네느 동일한 파티션으로 전송된다.

하지만, 이런 메시지 키와 파티션 할당은 프로듀서에서 설정된 파티셔너에 의해 결정되는데, 기본 파티셔너의 경우 이와 같은 동작을 보장한다.

커스텀 파티셔너를 사용할 경우에는 메시지 키에 따른 파티션 할당이 다르게 동작할 수 있다.

---

👀  파티션 개수가 늘어나면 새로 프로듀싱되는 레코드들은 어느 파티션으로 갈까?

메시지 키를 가진 레코드의 경우 파타신여ㅣ 추가되면 파티션과 메시지 키의 일관성이 보장되지 않는다.

만약, 파티션을 추가하더라도 이전에 사용하던 메시지 키의 일관성을 보장하고 싶다면 커스텀 파티셔너를 만들어서 운영해야 한다.
# 03. 저장소와 탐색

가장 기본적인 수준에서 데이터베이스는 데이터 저장과 데이터 제공을 수행
데이터베이스가 저장과 검색을 내부적으로 처리하는 방법을 애플리케이션 개발자가 주의해야 하는 이유
: 사용 가능한 여러 저장소 엔진 중에 애플리케이션에 적합한 엔진을 선택하는 작업이 필요

## 데이터베이스를 강력하게 만드는 데이터 구조

세상에서 가장 간단한 데이터베이스 with bash 함수

```bash
#!/bin/bash

db_set () {
    echo "$1,$2" >> database
}

db_get() {
    grep "^$1," database | sed -e "s\^$1,\\" | tail -n 1
}
```

키 값 저장소를 함수 2 개로 구현
기본적인 저장소 형식은 매우 간단
: 매 라인마다 쉼표로 구분된 키-값 쌍을 포함한 텍스트 파일
db_set을 호출할 때마다 파일의 끝에 추가하므로 키를 여러 번 갱신해도 값의 예전 버전을 덮어 쓰지 않는다.
최신 값을 찾기 위해서는 파일에서 키의 마지막 항목을 살펴봐야 한다.

일반적으로 파일 추가 작업은 매우 효율적이기 때문에 db_set 함수는 간단한 작업에서는 꽤 좋은 성능을 보여준다.
db_set과 마찬가지로 많은 데이터베이스는 내부적으로 추가 전용 데이터 파일인 로그(log)를 사용한다. (믿기지 않을 정도로 유용)

로그 : 조금 더 일반적인 의미로 연속된 추가 전용 레코드

db_get 함수는 데이터베이스에 많은 레코드가 있으면 성능이 매우 좋지 않음.
키가 있는지 찾기 위해 전체 데이터베이스 파일을 처음부터 끝까지 스캔
-> O(n)

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요
-> 색인

색인의 일반적인 개념 : 어떤 부가적인 메타데이터를 유지
-> 이정표 역할을 해서 원하는 데이터의 위치를 찾는 데 도움을 준다
색인은 기본 데이터에서 파생된 추가적인 구조로 데이터베이스의 내용에는 영향을 미치지 않는다.
단지 질의 성능에만 영향
추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생
어떤 종류의 색인이라도 대개 쓰기 속도를 느리게 만든다.
데이터를 쓸 때마다 매번 색인도 갱신해야 하기 때문
-> 저장소 시스템에서 중요한 트레이드오프
-> 애플리케이션의 전형적인 질의 패턴에 대한 지식을 활용해 수동으로 색인을 선택해야 함

### 해시 색인

키 값 저장소 : 사전 타입과 매우 유사, 보통 해시 맵으로 구현

단순히 파일에 추가하는 방식으로 데이터 저장소를 구성한다고 가정
이 때 가장 간단한 색인 전략
: 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략

파일에 새로운 키-값 쌍을 추가할 때마다 방금 기록한 데이터의 오프셋을 반영하기 위해 해시 맵도 갱신 필요
값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다.

하지만 파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다.
해결 방법
: 특정 크기의 세그먼트로 로그를 나누는 방식이 좋은 해결책
특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기를 수행.
세그먼트 파일들에 대해 컴팩션을 수행할 수 있다.
컴팩션 : 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것
보통 세그먼트를 더 작게 만들고 컴팩션을 수행할 때 동시에 여러 세그먼트들을 병합할 수 있다.
세그먼트가 쓰여진 이후에는 절대 변경할 수 없기 때문에 병합할 세그먼트는 새로운 파일로 만든다.
고정된 세그먼트의 병합과 컴팩션은 백그라운드 스레드에서 수행.
컴팩션 수행 도중에는 이전 세그먼트 파일을 사용해 읽기와 쓰기 요청의 처리를 정상적으로 수행.
병합 과정이 끝난 이후에는 읽기 요청은 이전 세그먼트 대신 새로 병합한 세그먼트를 사용하게끔 전환한다.
전환 후에는 이전 세그먼트 파일을 삭제

각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 갖는다.
키의 값을 찾으려면 최신 세그먼트 해시 맵을 먼저 확인한다.
병합 과정을 통해 세그먼트 수를 적게 유지하기 때문에 조회할 때 많은 해시 맵을 확인할 필요는 없다.

추가 전용 로그 장점

- 추가와 세그먼트 병합은 순차적인 쓰기 작업 -> 보통 무작위 쓰기보다 훨씬 빠르다
- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다

해시 테이블 색인의 제한 사항

- 메모리에 저장하므로 키가 너무 많으면 문제 : 디스크에 해시 맵을 유지할 수 있지만 좋은 성능 기대하긴 어려움. 무작위 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요함
- 범위 질의에 효율적이지 않다. 해시 맵에서 모든 개별 키를 조회해야 함.

## SS 테이블과 LSM 트리

세그먼트 파일의 형식에 간단한 변경 사항 한 가지를 적용해보자.
변경 요구사항 : 일련의 키-값 쌍을 키로 정렬
-> 이처럼 키로 정렬된 형식을 정렬된 문자열 테이블, Sorted Sorting Table이라 부른다.

각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다. (컴팩션 과정이 이를 보장))
SS 테이블은 해시 색일을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.

1. 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적. 병합정렬 방식과 유사
2. 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다. 키의 정확한 오프셋을 알지 못하더라더도 인접한 두 키의 오프셋을 알고 있으면 정렬 구조를 이용하여 찾을 수 있다.
3. 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축.

### SS테이블 생성과 유지

- 쓰기가 들어오면 인메모리 균형 트리 데이터 구조에 추가 -> 멤테이블이라 부름
- 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크에 기록. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있어 효율적 수행 가능. 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 됨.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 함. 그다음 디스크 상의 가장 최신 세그먼트에서 찾음. 그다음으로 두번째, 세번째 오래된 세그먼트에서 찾음.
- 병합과 컴팩션 과정을 백그라운드에서 수행.

하지만, 데이터베이스가 고장나면 아직 디스크로 기록되지 않고 멤테이블에 있는 가장 최신 쓰기는 손실됨.
따라서, 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 함.
이 로그는 손상 후 멤테이블을 복원할 때만 필요 -> 순서 정렬 필요 없음
멤테이블을 SS테이블로 기록하고 나면 해당 로그는 버릴 수 있음

### SS테이블에서 LSM 트리 만들기

로그 구조화 병합 트리 (Log-Structured Merge-Tree)
: 이 색인 구조는 로그 구조화 파일 시스템의 초기 작업의 기반
정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부름

### 성능 최적화

LSM 알고리즘은 데이터베이스에 존재하지 않는 키를 찾는 경우 느릴 수 있음
멤테이블을 확인 -> 키가 존재하지 않는다는 사실을 확인하기 전에는 가장 오래된 세그먼트까지 거슬러 올라가야 한다.
블룸 필터는 이런 종류의 접근을 최적화하기 위해 사용 가능.
: 집합 내용을 근사한 메모리 효율적 데이터 구조. 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 위한 불필요한 디스크 읽기를 많이 절약할 수 있다.

SS테이블을 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략

- 크기 계층 컴팩션 : 상대적으로 좀 더 새롭고 작은 SS테이블을 상대적으로 오래됐고 큰 SS테이블에 연이어 병합
- 레벨 컴팩션 : 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 레벨로 이동, 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용

LSM 트리의 기본 개념은 간단하고 효과적
: 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것
-> 데이터셋이 가능한 메모리보다 훨씬 더 크더라도 여전히 효과적.
데이터가 정렬된 순서로 저장돼있다면 범위 질의를 효율적으로 실행 가능.
이 접근법의 디스크 쓰기는 순차적이기 때문에 LSM트리가 매우 높은 쓰기 처리량을 보장할 수 있음

## B 트리

가장 널리 사용되는 색인 구조 : B 트리 (로그 구조화 색인과는 상당히 다름)
대부분 관계형 데이터베이스의 표준 색인 구현.
SS테이블과 같이 키로 정렬된 키-값 쌍을 유지 -> 키-값 검색과 범위 질의에 효율적이다.
하지만, B트리는 설계 철학이 로그 구조화 색인과 매우 다르다.
로구 구조화 색인은 데이터베이스를 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다.
B 트리는 전통적으로 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다.
디스크가 고정 크기 블록으로 배열되기 때문에 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.
각 페이지는 주소나 위치를 이용해 식별 -> 하나의 페이지가 다른 페이지를 참조할 수 있음
한 페이지는 B 트리의 루트로 지정.
색인에서 키를 찾으려면 루트에서 시작
페이지는 여러 키와 하위 페이지의 참조를 포함
각 하위 페이지는 키가 계속 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타냄.
최종적으로 개별 키(Leaf Page)를 포함하는 페이지에 도달.
B 트리의 한 페이지에서 하위 페이지를 참조하는 수 : 분기 계수, 보통 수백 개

B 트리에 존재하는 키의 값을 갱신하려면 키를 포함하고 있는 리프 페이즈를 검색하고 페이지의 값을 바꾼 다움 페이지를 디스크에 다시 기록.
새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가. 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신.
이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장.
n개의 키를 가진 B 트리는 깊이가 항상 O(log n)
대부분의 데이터베이스는 B 트리의 깊이가 3이나 4단계 정도면 충분. -> 검색하려는 페이지를 찾기 위해 많은 페이지 참조를 따라가지 않아도 됨.

### 신뢰할 수 있는 B 트리 만들기

B 트리의 기본적인 쓰기 동작 : 새로운 데이터를 디스크 상의 페이지에 덮어쓰기
이 동작은 덮어쓰기가 페이지 위치를 변경하지 않는다고 가정한다.
즉 페이지를 덮어쓰더라도 페이지를 가리키는 모든 참조는 온전하게 남는다.
LSM 트리와 같은 로그 구조화 색인과는 아주 대조적인 점이다. 로그 구조화 색인은 파일에 추가만할 뿐 같은 위치의 파일은 변경하지 않는다.

일부 동작은 여러 다양한 페이지의 덮어쓰기를 필요로 한다.
일부 페이지만 기록하고 데이터베이스가 고장난다면 결국 색인이 훼손되기 때문에 이것은 매우 위험한 동작.
데이터베이스가 고장 상황에서 스스로 복구할 수 있게 만드려면 일반적으로 디스크 상에 쓰기 전 로그 (Write Ahead Log)라고 하는 데이터 구조를 추가해 B트리를 구현한다. 쓰기 전 로그는 트리 페이지에 변경된 내용을 적용하기 전에 모든 B 트리의 변경 사항을 기록하는 추가 전용 파일이다.
고장 이후 복구될 때 일관성 있는 상태로 B 트리를 다시 복원하는데 사용

동시성 제어는 보통 래치(가벼운 잠금)로 트리의 데이터 구조를 보호한다.

### B 트리 최적화

- 페이지 덮어 쓰기와 고장 복구를 위한 WAL 유지 대신 일부 데이터베이스는 쓰기 시 복사 방식을 사용. 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 함. 동시성 제어에도 유용
- 페이지에 전체 키를 저장하는게 아니라 키를 축약해 쓰면 공간 절약 가능. 페이지 하나에 더 많은 키를 채우면 트리는 더 높은 분기 계수를 얻는다. 그러면 트리 깊이 수준을 낮출 수 있음
- 일반적으로 페이지는 디스크 상 어디에나 위치할 수 있다. 많은 B 트리 구현에서 리프 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리를 배치하려 시도. 반대로 LSM 트리는 병합하는 과정에서 저장소의 큰 세그먼트를 한 번에 다시 쓰기 때문에 디스크에서 연속된 키를 서로 가깝게 유지하기 더 쉽다
- 트리에 포인터를 추가하여 상위 페이지로 이동하지 않아도 순서대로 키를 스캔 가능

### B 트리와 LSM 트리 비교

B 트리가 LSM 트리보다 일반적으로 구현 성숙도가 더 높지만 LSM 트리도 그 성능 특성 때문에 관심 받고 있음
경험적으로 LSM 트리는 보통 쓰기에서 더 빠른 반면 B 트리는 읽기에서 더 빠르다고 여김
읽기가 보통 LSM 트리에서 더 느린 이유 : 각 컴팩션 단계에서 있는 여러 가지 데이터 구조와 SS테이블을 확인해야 하기 때문

### LSM 트리의 장점

B 트리 색인은 모든 데이터 조각을 최소한 두 번 기록해야 함.
쓰기 전 로그 한 번과 트리 페이지에 한 번.

로그 구조화 색인 또한 SS테이블의 반복된 컴팩션과 병합으로 인해 여러 번 데이터를 다시 쓴다. 데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 디스크에 여러 번의 쓰기를 야기하는 이런 효과 : 쓰기 증폭

쓰기가 많은 애플리케이션에서 성능 병목은 데이터베이스가 디스크에 쓰는 속도일 수 있다.
이 때 쓰기 증폭은 바로 성능 비용
LSM 트리는 보통 B 트리보다 쓰기 처리량을 높게 유지할 수 있다.
상대적으로 쓰기 증폭이 더 낮고 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS테이블 파일을 쓰기 때문 (자기 하드드라이브에서 순차 쓰기가 임의 쓰기보다 훨씬 더 빠름)

LSM 트리는 압축률이 더 좋다. 보통 B 트리보다 디스크에 더 적은 파일을 생성
페이지 지향적이지 않고 주기적으로 파편화를 없애기 위해 SS테이블을 다시 기록하기 때문에 저장소 오버헤드가 더 낮음

### LSM 트리의 단점

로그 구조화 저장소의 단점 : 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다는 점
저장소 엔진은 컴팩션을 점진적으로 수행하고 동시 접근의 영향이 없게 수행하려 함.
하지만 디스크가 가진 자원은 한계 존재.
-> 디스크에서 비싼 컴팩션 연산이 끝날 때까지 요청이 대기해야 하는 상황이 발생하기 쉬움
처리량과 평균 응답 시간이 성능에 미치는 영향은 대개 작다.
하지만, 로그 구조화 저장소 엔진의 상위 백분위 질의의 응답 시간은 때때로 꽤 길다.
반면 B 트리의 성능은 로그 구조화 저장소 엔진보다 예측하기 쉬움

또 다른 컴팩션 문제 : 높은 쓰기 처리량에서 발생
디스크의 쓰기 대역폭은 유한하지만 데이터베이스가 점점 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요

쓰기 처리량이 높음에도 컴팩션 설정을 주의 깊게 하지 않으면 컴팩션이 유입 쓰기 속도를 따라갈 수 없다. 이 경우 디스크 상에 병합되지 않은 세그먼트 수는 디스크 공간이 부족할 때까지 증가. 명시적 모니터링이 필요

B 트리의 장점 : 각 키가 색인의 한 곳에만 정확하게 존재한다는 점
반면 로그 구조화 저장소 엔진은 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다. 이런 측면 때문에 강력한 트랜잭션 시멘틱을 제공하는 데이터베이스에는 B 트리가 더 매력적.

# 06. 파티셔닝

대체로 각 데이터 단위를 1개의 파티션으로 만든다.
그 자체로 1개의 작은 데이터베이스.
파티셔닝을 하는 주 된 원인은 확장성

단일 파티션에 실행되는 질의를 각 노드에서 자신의 파티션으로 해당 질의를 독립적으로 실행하게 되면
-> 노드를 추가할 때마다 질의 처리량이 증가

## 파티셔닝과 복제

1개의 노드에 여러 파티션이 존재 가능
각 노드에서 각 파티션은 리더일 수도 있고 팔로워일 수도 있다.
: 리더-팔로워 복제 모델

## 키-값 데이터 파티셔닝

파티셔닝 : 데이터와 질의 부하를 각 노드에 균등하게 분산시키는 것
동일한 분량을 담당한다는 가정 하에 1개의 노드가 10개의 노드가 되면
-> 10배의 데이터를 저장할 수 있고, 10배의 읽기, 쓰기 요청에 대한 처리가 가능

쏠림 : 파티셔닝이 고르게 이루어지지 않아 다른 파티션보다 데이터가 많거나 질의 처리를 많이 하는 파티션이 존재하는 경우
핫스팟 : 불균형하게 부하가 높은 파티션

핫스팟을 해결하는 가장 쉬운 방법
: 데이터 저장 시 무작위로 분산하여 저장
-> 데이터를 모두 고르게 분산할 수 있지만, 데이터 탐색 시 모든 노드에서 병렬적으로 탐색을 수행해야 함

키-값 데이터 모델
: 항상 기본 키를 통해 레코드에 접근
-> 항상 빨리 찾을 수 있다.
ex) 백과사전

## 키 범위 기준 파티셔닝

파티셔닝 방법 : 백과사전
각 파티션에 연속된 범위의 키를 할당
-> 각 범위의 경계를 알면 데이터를 어디에 저장했는지 파악이 쉬움
(어느 키가 어느 파티션에 속하는지)

각 파티션이 어느 노드에 할당되어 있는지 알면 적절한 노드로 요청도 가능

키 범위가 파티션별로 동일할 필요는 없다.
데이터에 맞게 범위는 조정되어야 한다.
그렇지 않으면 데이터 쏠림 현상이 발생할 수 있다.

각 파티션 내에서 키는 정렬된 순서로 유지된다.
그로 인해 빠르게 탐색이 가능하다.
하지만, 키 범위 기준 파티셔닝은 특정 접근 패턴에 대해 핫스팟을 유발할 수 있다.
예를 들어, 타임스팸프가 키라면 해당 날짜에 대한 파티션만 부하를 받고 나머지는 유휴 상태로 유지

## 키의 해시값 기준 파티셔닝

쏠림과 핫스팟 위험때문에 많은 분산 데이터 스토어는 키의 파티션을 정하는데 해시함수를 적용
좋은 해시 함수 : 쏠린 데이터를 균일하게 분산
암호적으로 강력할 필요는 없다.
ex) 카산드라와 몽고DB : MD5, 볼드모트 : 파울러-놀-보
프로그래밍 언어에서 지원하는 내장 해시 함수는 파티셔닝에는 적합 X

각 파티션에 해시값 범위 할당하고, 해시값이 파티션 범위에 속하는 모든 키를 해당 파티션에 할당
-> 키를 파티션에 균일하게 분산시키기에 좋음
하지만, 키의 해시값으로 파티셔닝하면 범위 질의를 효율적으로 실행할 수 있는 키 범위 파티셔닝의 장점을 잃어버림
-> 인접했던 키들이 모든 파티션에 흩어져서 정렬 순서가 유지되지 않기 때문
-> 해시값으로 파티셔닝하면 범위 질의가 모든 파티션에 전송되어야 함

카산드라는 두 가지 파티셔닝(키 범위 기준 파티셔닝, 키의 해시값 기준 파티셔닝)에서 타협

- 여러 칼럼을 포함하는 복합 기본키 지정

첫 번째 키에만 해싱을 적용해 파티션 결정에 사용
남은 키에는 데이터를 정렬하는 연쇄된 색인으로 사용
-> 복합 키의 첫 번째 칼럼에 대해서 값 범위로 검색하는 질의는 사용 불가
-> 하지만, 첫 번째 칼럼에 고정된 값 적용하면 다른 칼럼에 대해서는 효율적인 범위 스캔 가능

이로인해 연쇄된 색인을 사용하면 일대다 관계를 표현하는 우아한 데이터 모델 설계 가능

## 쏠린 작업부하와 핫스팟 완화

키의 해시값으로 파티셔닝 -> 핫스팟을 줄이는데 도움
하지만, 핫스팟을 완벽히 제거는 불가능
항상 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.
ex) SNS에서 수 백만명의 팔로워를 거느린 유명인의 행동
(동일한 ID의 해시값은 동일 -> 해싱은 도움 X)

현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정 불가능
-> 애플리케이션에서 쏠림을 완화해야 함.
요청이 매우 많이 쏠리는 키를 발견했을 때의 간단한 해결책
: 각 키의 시작이나 끝에 임의의 숫자를 붙이는 것
이로써 한 키에 대한 쓰기 작업이 여러 개의 다른 키로 균등하게 분산, 그 키들은 다른 파티션으로 분산
하지만, 다른 키에 쪼개서 쓰면 발생하는 단점
: 추가적인 작업 필요

- 여러 개의 키에 해당하는 데이터를 읽어서 조합해야 함 & 추가적으로 저장해야 할 정보도 존재
  -> 요청이 몰리는 소수의 키에만 적용하는 게 타당
  쓰기 처리량이 낮은 대다수의 키에도 적용 시 불필요한 오버헤드 발생

## 파티셔닝과 보조 색인

키-값 데이터 모델로 파티셔닝을 진행
레코드를 기본 키를 통해 접근하여 읽기/쓰기 요청을 전달

보조 색인이 연관되면 복잡해진다.

보조 색인 (ex. like %hogual%, color = 'RED')

- 레코드를 유일하게 식별하는 용도 X
- 특정 값이 발생한 항목을 검색하는 수단
- 관계형 데이터베이스의 핵심 요소
- 엘라스틱 서치와 같은 검색 서버에게는 존재의 이유
- 파티셔닝에 깔끔하게 대응되지 않음

보조 색인이 존재하는 데이터베이스를 파티셔닝하는 방법

- 문서 기준 보조 색인 파티셔닝
- 용어 기준 보조 색인 파티셔닝

### 문서 기준 보조 색인 파티셔닝

- 각 파티션 별로 독립적으로 운영
- 각 파티션 별로 자신의 보조 색인을 유지하며 해당 파티션에 속하는 문서만 담당
- 쓰기 작업 시 해당하는 파티션에만 작업이 발생하므로 쓰기 작업에 대한 비용이 낮음
  -> 지역 색인

하지만, 문서 기준 보조 색인 파티셔닝 시에는 읽기에 대한 부담이 존재.
특정 값에 해당하는 데이터가 동일한 파티션에 저장되리라는 보장이 없음
-> 특정 값을 찾기 위해 모든 파티션에 질의를 요청하여 얻은 결과를 모아야 함
-> 스캐더/개더 (scatter / gather)
보조 색인을 사용해서 읽는 질의는 큰 비용이 들게 됨

여러 파티션에서 질의를 병렬 실행하더라도 스캐더/개더는 꼬리 시간 지연 증폭이 발생하기 쉬움
하지만, 많은 데이터베이스에서 보조 색인을 문서 기준으로 파티셔닝하는 경우가 많다.

### 용어 기준 보조 색인 파티셔닝

용어 : 문서에 존재하는 모든 단어
용어 기준 보조 색인 파티셔닝
: 찾고자 하는 용어에 따라 색인의 파티션이 결정되는 파티셔닝 방법
모든 파티션의 데이터를 담당하는 전역 색인을 만듦
한 노드에만 색인을 저장하지 않음 (해당 노드가 병목이 되어 파티셔닝의 목적을 해침)
전역 색인 자체를 파티셔닝할 수 있음

파티셔닝 방법

- 용어 자체
  - 범위 스캔에 적합
- 용어의 해시 값
  - 부하 분산에 적합

용어를 포함하는 파티션으로만 요청을 보내면 되기 때문에 읽기가 효율적임
하지만, 쓰기가 느리고 복잡함
단일 문서를 쓸 때 해당 색인의 여러 파티션에 영향을 줄 수 있기 때문 (문서에 있는 모든 용어가 다른 노드에 있는 다른 파티션에 속할 수 있음)
따라서, 대개 비동기로 갱신 (이론적으로는 분산 트랜잭션으로 실행해야 하지만, 모든 데이터베이스에서 지원하지 않음)

## 파티션 재균형화

- 질의 처리량 증가 -> 늘어난 부하 처리 필요 -> CPU 추가
- 데이터셋 크기 증가 -> 데이터 저장에 사용될 디스크와 램 추가
- 장비에 장애 발생 -> 역할을 다른 장비가 넘겨받아야 함
  이런 변화가 발생하면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다.

-> 재균형화
: 클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정

재균형화의 최소 요구사항

- 재균형화 후 부하는 클러스터 내의 모든 노드들 사이에 균등하게 분배되어야 함
- 재균형화 도중에도 읽기 쓰기 요청을 받아들여야 함
- 재균형화가 빨리 실행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에서 필요 이상으로 데이터 이동이 발생해서는 안됨

### 재균형화 전략

#### 쓰면 안 되는 방법 : 해시 값에 모드 N 연산을 실행

키의 해시값 기준으로 파티셔닝 시 사용 가능한 해시값 범위를 나누고 각 범위를 한 파티션에 할당하는 게 최선
-> 왜 모드 연산을 사용하지 않을까?
예를 들어, 노드 10대가 있고 각각 0부터 0까지 숫자를 배정하면 각 키를 노드에 할당하는 것은 매우 쉬움

모드 N 방식의 문제
: 노드 개수 N이 바뀌면 대부분의 키가 노드 사이에 옮겨져야 한다는 점
노드가 10대일 때랑, 11대, 12대일 때 키가 계속 노드 사이에서 옮겨져야 한다.
-> 키가 자주 이동하면 재균형화 비용이 지나치게 커진다.

#### 파티션 개수 고정

파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당
예) 노드 10대로 구성된 클러스터에서 실행되는 데이터베이스, 1000개의 파티션으로 쪼개고 각 노드마다 약 100개의 파티션 할당

클러스터에 노드 추가
-> 새 노드는 파티션이 다시 균일하게 분배될 때까지 기존 노드에서 파티션 몇 개를 뺏어옴
클러스터에서 노드 제거
-> 기존 노드의 파티션을 다른 노드로 분배

파티션은 노드 사이에서 통째로 이동하기만 한다.
파티션 개수는 변경 X, 파티션에 할당된 키도 변경 X
유일한 변화 : 노드에 어떤 파티션이 할당되는가

파티션 할당 변경은 즉시 반영되지 않고 네트워크를 통해 대량의 데이터를 전송해야 함
-> 시간이 좀 걸리는 작업
-> 데이터 전송이 진행 중인 동안에 읽기나 쓰기가 실행되면 기존에 할당된 파티션을 사용한다.

리악, 엘라스틱서치, 카우치베이스, 볼드모트에서 파티션 개수 고정 재균형화 방법 사용

보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변화하지 않는다.
-> 파티션 개수 고정 -> 운영 단순
-> 처음 설정된 파티션 개수가 사용 가능한 노드 대수의 최대치
-> 미래에 증가될 것을 수용하기에 충분히 높은 값으로 선택

#### 동적 파티셔닝

키 범위 파티셔닝을 사용하는 데이터베이스에서 파티션 경계와 개수가 고정되어 있는 것은 매우 불편
파티션 경계를 잘못 지정하면 모든 데이터가 한 파티션에 저장되고 나머지 파티션은 더 빌 수도 있다.
(예. 날짜로 파티셔닝 시 해당 날짜가 아니면 비어있음)
-> 키 범위 파티셔닝 사용 데이터베이스는 동적으로 파티션을 만든다.

파티션 크기가 설정된 값을 넘어서면 파티션을 두 개로 쪼개 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다.
데이터가 많이 삭제되어 파티션 크기가 임곗값 아래로 떨어지면 인접한 파티션과 합쳐질 수 있다.
(B 트리의 최상위 레벨에서 실행되는 작업과 유사)

파티션 개수가 고정된 경우와 마찬가지로 각 파티션은 노드 하나에 할당되고 각 노드는 여러 파티션을 담당할 수 있다.

동적 파티셔닝의 이점
: 파티션 개수가 전체 데이터 용량에 맞춰 조정된다

데이터 양이 작으면 파티션 개수도 적어도 되므로 오버헤드도 적다.
데이터 양이 거대하면 개별 파티션의 크기는 설정된 최대치로 제한된다.

하지만, 빈 데이터베이스의 경우 파티션 경계를 어디로 정해야 하는지에 관한 사전 정보가 없음
-> 파티션이 1개
-> 데이터 셋이 작을 때는 모든 쓰기 요청이 하나의 노드에서 실행되고 다른 노드들은 유휴 상태
-> 이 문제를 완화하기 위해 빈 데이터베이스에 초기 파티션 집합을 설정할 수 있음
: 사전 분할
(키 범위 파티셔닝의 경우 사전 분할을 하려면 키가 어떤 식으로 분할될지 미리 알아야 함)

동적 파티셔닝은 키 범위 파티셔닝에만 적합한 것은 아니고 해시 파티셔닝에도 똑같이 사용될 수 있음

#### 노드 비례 파티셔닝

파티션 개수가 노드 대수에 비례하도록 파티셔닝
-> 노드당 할당되는 파티션 개수를 고정
-> 노드 대수가 변함 없는 동안은 개벌 파티션의 크기가 데이터셋 크기에 비례해서 증가
-> 노드 대수를 늘리면 파티션의 크기는 작아진다.
데이터 용량이 클수록 데이터를 저장할 노드도 많이 필요
-> 개별 파티션 크기도 상당히 안정적으로 유지
(카산드라와 케티마에서 사용)

새 노드가 클러스터에 추가되면
-> 고정된 개수의 파티션을 무작위로 선택해 분할
-> 각 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당
파티션을 무작위로 분할해 균등하지 않은 분할이 생길 수 있지만, 여러 파티션에 대해 평균적으로 보면 새 노드는 기존 노드들이 담당하던 부하에서 균등한 몫을 할당받게 된다.

파티션 경계를 무작위로 선택하려면 해시 기반 파티셔닝을 사용해야 한다.
(해시 함수를 통해 생성된 숫자 범위로부터 파티션 경게를 선택할 수 있도록)

## 요청 라우팅

클라이언트에서 요청을 어디로 보내야하지?
-> 요청을 처리할 수 있는 노드는 어디에 있지?
-> 서비스 찾기 : Service Discovery
고가용성을 지향하는 소프트웨어에서 고민해야하는 문제

Service Discovery 방법

1. 클라이언트에서 아무 노드에게 요청

- 해당 노드가 처리 가능하면 처리하고, 불가능하면 처리 가능한 노드에게 요청 전달

2. 클라이언트가 라우팅 계층으로 요청

- 라우팅 계층이 요청을 처리할 수 있는 노드로 요청을 전달

3. 클라이언트가 요청을 처리할 수 있는 노드를 알고 있어 직접 해당 노드로 요청

많은 분산 데이터 시스템은 클러스터 메타데이터를 추적하기 위해 주키퍼와 같은 별도의 코디네이션 서비스 사용
각 노드는 주키퍼에 자신을 등록 & 주키퍼는 파티션과 노드 사이의 신뢰성 있는 할당 정보를 관리
라우팅 계층이나 파티션 인지 클라이언트 같은 다른 구성 요소들은 주키퍼에 있는 정보를 구독
파티션의 소유주 변경, 노드 추가, 삭제에 대해 주키퍼는 라우팅 계층에 이를 알려서 라우팅 정보를 최신으로 유지하도록 함

카프카 : 주키퍼 사용
몽고DB : 자체 설정 서버 사용, 몽고스 데몬을 라우팅 계층으로 사용
카산드라 : 가십 프로토콜 사용 -> 클러스터 상태 변화를 노드에 퍼뜨림
-> 1번 방식과 같이 아무 노드나 요청을 받을 수 있고 올바른 노드에게 요청 전달
-> 데이터베이스 노드에 복잡성 증가 but, 외부 코디네이션 서비스 의존 X

## 병렬 질의 실행

MPP : Massively Parallel Processing
대규모 병렬 처리 -> 분석용으로 자주 사용

복잡한 질의를 여러 실행단계와 파티션으로 분해
-> 서로 다른 노드에서 병렬적으로 처리

## 정리

저장하고 처리할 데이터가 너무 많아서 장비 한 대로 처리하는게 불가능
-> 파티셔닝 필요

파티셔닝의 목적
: 핫스팟이 생기지 않게 하면서 데이터와 질의 부하를 여러 장비에 균일하게 분배

파티셔닝 기법

1. 키 범위 파티셔닝
   : 키가 정렬되어있고 개별 파티션은 어떤 최솟값과 최댓값 사이에 속하는 모든 키를 담당

- 범위 질의 효율적 (키 순서 보장 O)
- 정렬 순서가 서로 가까운 키에 자주 접근 시 핫스팟 생김

2. 해시 파티셔닝
   : 각 키에 해시 함수를 적용, 각 파티션은 특정 범위의 해시값을 담당

- 범위 질의 비효율적 (키 순서 보장 X)
- 부하를 더욱 고르게 분산 가능
- 해시 파티셔닝 사용 시 보통 고정된 개수의 파티션을 미리 만들어 각 노드에 몇 개씩 파티션을 할당하며 노드가 추가되거나 제거되면 파티션을 통째로 노드 사이에서 이동

두 가지 파티셔닝 전략을 섞어서 사용 가능
: 키의 일부분은 파티션 식별용, 나머지 부분은 정렬 순서용으로 만든 복합키 사용
예) 카산드라

보조 색인 파티셔닝 기법

- 문서 기반 보조 색인 파티셔닝 (지역 색인)
  : 보조 색인을 기본 키와 값이 저장된 파티션에 저장
  -> 쓸 때는 하나의 파티션만 갱신
  -> 읽을 때 모든 파티션에 걸쳐 스캐더/개더 실행
- 용어 기반 보조 색인 파티셔닝 (전역 색인)
  : 색인된 값을 사용하여 보조 색인을 별도로 파티셔닝
  -> 보조 색인 항목은 기본키의 모든 파티션에 있는 레코드를 포함할 수도 있음
  -> 쓸 때는 보조 색인 여러 개를 갱신
  -> 읽기는 단일 파티션에서 실행

# 07. 트랜잭션

시스템의 신뢰성 : 결함을 처리하여 전체 시스템의 치명적인 장애로 이어지는 것을 막아야 함
트랜잭션은 시스템의 신뢰성에 대한 문제를 단순화하는 메커니즘으로 채택되어 왔다.

트랜잭션 : 애플리케이션에서 몇 개의 읽기와 쓰기를 하나의 논리적 단위로 묶는 방법
-> 1개의 트랜잭션 내 모든 읽기와 쓰기는 1개의 연산으로 실행
-> 전체가 성공하거나 실패한다.

따라서, 트랜잭션이 실패한다면 애플리케이션에서 안전하게 재시도 가능
(부분적인 실패를 걱정하지 않아도 되기 때문)

## 애매모호한 트랜잭션의 개념

현대의 거의 모든 관계형 데이터베이스와 일부 비관계형 데이터베이스는 트랜잭션을 지원한다.
2000년대 후반 비관계형 데이터베이스가 인기를 끌기 시작하면서 대다수는 트랜잭션을 지원하지 않았다.
-> 트랜잭션은 확장성의 안티체제이며 높은 성능과 고가용성 유지를 위해서는 트랜잭션을 포기해야한다는 믿음이 생김

하지만, 아니다

### ACID의 의미

트랜잭션이 제공하는 안전성 보장 : ACID

- Atomicity : 원자성
- Consistency : 일관성
- Isolation : 격리성
- Durability : 지속성

ACID 표준을 따르지 않는 시스템을 때로 BASE로 부름

- Basically Available : 기본적으로 가용성 제공
- Soft State : 유연한 상태
- Eventually Consistency : 최종적 일관성

#### 원자성, Atomicity

원자적 : 더 작은 부분으로 쪼갤 수 없는 무언가
예) 다중 스레드 프로그래밍에서 한 스레드가 원자적 연산을 실행 -> 다른 스레드에서 절반만 완료된 연산을 관찰할 수 없음
시스템은 연산을 실행하기 전이나 실행한 후의 상태만 존재하고 그 중간 상태에는 머물 수 없다.

ACID의 맥락에서 원자성은 동시성과 관련이 없다.
원자성은 여러 프로세스가 동시에 같은 데이터에 접근하려고 할 때 무슨 일이 생기는지 설명하지 않는다.
-> 이 문제는 격리성과 관련이 있다.

원자성은 클라이언트가 쓰기 작업 몇 개를 실행하려고 하는데 그 중 일부만 처리된 후 결함이 발생하면 무슨 일이 생기는지 설명한다.
여러 쓰기 작업이 하나의 원자적인 트랜잭션으로 묶여 있는데 결함 때문에 완료될 수 없다면 어보트 되고 데이터베이스는 이 트랜잭션에서 지금까지 실행한 쓰기를 무시하거나 취소해야 한다.

원자성이 없으면 애플리케이션에서 동일한 변경이 2번 실행되어서 중복되거나 잘못된 데이터가 만들어지기 쉽다.
-> 원자성은 이 문제를 단순하게 만들어준다.

오류가 생겼을 때 : 트랜잭션을 어보트, 해당 트랜잭션에서 기록한 모든 내용을 취소하는 능력
-> 원자성의 결정적인 특징

#### 일관성, Consistency

ACID의 맥락에서 일관성 : 데이터베이스가 좋은 상태에 있어야 한다는 것의 애플리케이션에 특화된 개념
일관성의 아이디어 : 항상 진실이어야 하는 데이터에 관한 어떤 선언이 있다는 것
예) 회계 시스템에서 모든 계좌에 걸친 대변과 차변은 항상 맞아떨어져야 한다.
트랜잭션이 이런 불변식이 유효한 데이터베이스에서 시작하고 트랜잭션에서 실행된 모든 쓰기가 유효성을 보존한다면 불변식이 항상 만족된다고 확신 가능

일관성의 아이디어는 애플리케이션의 불변식 개념에 의존하고, 일관성을 유지하도록 트랜잭션을 올바르게 정의하는 것은 애플리케이션의 책임이다.
-> 데이터베이스가 보장할 수 있는 것이 아님

원자성, 격리성, 지속성은 데이터베이스의 속성 but, 일관성은 애플리케이션의 속성
애플리케이션에서 일관성을 달성하기 위해 데이터베이스의 원자성과 격리성 속성에 기댈 수는 있지만 데이터베이스만으로 되는 것은 아니다.

#### 격리성, Isolation

대부분 동시에 여러 클라이언트에서 데이터베이스에 접속한다.
-> 동일한 데이터베이스 레코드에 접근하면 동시성 문제(경쟁 조건, Race Condition)에 맞닥뜨리게 된다.

ACID에서 격리성 : 동시에 실행되는 트랜잭션은 서로 격리된다는 것을 의미
트랜잭션은 다른 트랜잭션을 방해할 수 없다.
고전적인 데이터베이스 교과서에서는 격리성을 직렬성이라는 용어로 공식화한다.
직렬성 : 각 트랜잭션이 전체 데이터베이스에서 실행되는 유일한 트랜잭션인 것처럼 동작할 수 있다는 것을 의미
-> 데이터베이스는 실제로는 여러 트랜잭션이 동시에 실행됐더라도 트랜잭션이 커밋되었을 때의 결과가 트랜잭션이 순차적으로 실행됐을 때의 결과와 동일하도록 보장한다.

하지만, 직렬성 격리(Serializable Isolation)은 성능 손해를 동반 -> 현실에서는 거의 사용하지 않음

#### 지속성, Durability

지속성 : 트랜잭션이 성공적으로 커밋됐다면 하드웨어 결함이 발생하거나 데이터베이스가 죽더라도 트랜잭션에서 기록한 모든 데이터는 손실되지 않는다는 보장
지속성을 보장하려면 데이터베이스는 트랜잭션이 성공적으로 커밋됐다고 보고하기 전에 쓰기나 복제가 완료될 때까지 기다려야 한다.

### 단일 객체 연산과 다중 객체 연산

다중 트랜잭션 : 어떤 읽기 연산과 쓰기 연산이 동일한 트랜잭션에 속하는지 알아낸 수단이 있어야 한다.
관계형 데이터베이스에서는 클라이언트와 데이터베이스 서버 사이의 TCP 연결을 기반으로
어떤 특정 연결 내에서 BEGIN TRANSACTION 문과 COMMIT 문 사이의 모든 것은 같은 트랜잭션에 속하는 것으로 여겨진다.
반면, 비관계형 데이터베이스는 이런 식으로 연산을 묶는 방법이 없는 경우가 많다.
-> 어떤 키에 대한 연산은 성공하고 나머지 키에 대한 연산은 실패해서 데이터베이스가 부분적으로 갱신된 상태가 될 수 있다.

#### 단일 객체 쓰기

단일 객체 수준에서 원자성과 격리성을 제공하는 것을 목표
원자성은 장애 복구용 로그를 써서 구현할 수 있고, 격리성은 각 객체에 잠금을 사용해 구현할 수 있다.
데이터베이스의 증가 연산 : 더 복잡한 원자적 연산
compare-and-set은 변경하려는 값이 누군가에 의해 동시에 바뀌지 않았을 때만 쓰기가 반영되도록 허용한다.
단일 객체 연산은 여러 클라이언트에서 동시에 같은 객체에 쓰려고 할 때 갱신 손실을 방지하므로 유용하다.
하지만, 일반적으로 쓰이는 의미의 트랜잭션은 아니다.
트랜잭션은 보통 다중 객체에 대한 다중 연산을 하나의 실행 단위로 묶는 매커니즘으로 이해된다.

#### 다중 객체 트랜잭션의 필요성

많은 분산 데이터스토어는 다중 객체 트랜잭션 지원을 포기
-> 여러 파티션에 걸쳐서 구현하기 어렵고 매우 높은 가용성과 성능이 필요한 곳에서는 방해가 되는 시나리오도 존재.

#### 오류와 어보트 처리

트랜잭셤의 핵심 기능 : 오류 발생 -> 어보트되고 안전학 ㅔ재시도 가능
ACID 데이터베이스는 이 철학을 바탕으로 함
하지만, 모든 시스템이 이 철학을 따르지는 않음
-> 리더 없는 복제를 사용하는 데이터스토어 : 최선을 다하는 원칙을 기반으로 훨씬 더 많은 일을 함
: 데이터베이스는 가능한 모든 것을 할 것이며 그 때문에 오류가 발생하면 이미 한 일은 취소하지 않는다.
-> 오류 복구는 애플리케이션에게 책임이 있다.

오류는 필연적으로 발생하지만 많은 소프트웨어 개발자들은 오류 처리의 복잡한 내용은 신경쓰지 않고 낙관적인 상황만 생각하려고 한다.
인기있는 객체 관계형 매핑 프레임워크들은 어보트된 트랜잭션을 재시도하지 않는다.
어보트의 취지는 안전하게 재시도를 할 수 있게 하는데 있다.
하지만, 어보트된 트랜잭션을 재시도하는 것은 간단하고 효과적인 오류 처리 매커니즘이지만 완벽하지는 않다.

- 중복 발생 가능
- 과부화로 인한 오류 발생이라면 상황을 악화
- 영구적인 오류는 재시도해도 소용이 없음
  등등

## 완화된 격리 수준

동시성 문제 : 트랜잭션이 다른 트랜잭션에서 동시에 변경한 데이터를 읽거나 두 트랜잭션이 동시에 같은 데이터를 변경하려고 할 때만 나타난다.
데이터베이스는 오랫동안 트랜잭션 격리를 제공함
-> 애플리케이션 개발자들에게 동시성 문제를 감추려고 했다.
직렬성 격리 : 데이터베이스가 여러 트랜잭션들이 직렬적으로 실행되는 것과 동일한 결과가 나오도록 보장한다는 것을 의미
하지만, 성능 비용이 있고 많은 데이터베이스들은 그 비용을 지불하려고 하지 않는다.
-> 완화된 격리 수준을 사용하는 시스템들이 흔하다.

### 커밋 후 읽기

가장 기본적인 수준의 트랜잭션 격리 : Read Committed

1. 데이터베이스에서 읽을 때 커밋된 데이터만 보게 된다 (No Dirty Read)
2. 데이터베이스에 쓸 때 커밋된 데이터만 덮어쓰게 된다 (No Dirty Write)

#### 더티 읽기 방지

더티 읽기 : 다른 트랜잭션에서 커밋되지 않은 데이터를 볼 수 있는 것

Read Committed에서는 더티 읽기를 막아야 함
더티 읽기는 막는 게 유용한 이유

- 트랜잭션이 여러 객체를 갱신하는데 더티 읽기가 발생 -> 다른 트랜잭션이 일부는 갱신된 값을, 일부는 갱신되지 않은 값을 볼 수 있다.
- 트랜잭션이 어보트되면 그 때까지 쓴 내용은 모두 롤백 -> 실제로는 데이터베이스에 결코 커밋되지 않을 데이터를 볼 수 있다.

#### 더티 쓰기 방지

더티 쓰기 : 먼저 쓴 내용이 아직 커밋되지 않은 트랜잭션에서 쓴 것이고 나중에 실행된 쓰기 작업이 커밋되지 않은 값을 덮어써버리는 것

Read Committed에서는 더티 쓰기를 막아야 함
보통 먼저 쓴 트랜잭션이 커밋되거나 어보트될 때까지 두 번째 쓰기는 지연시키는 방법을 사용

#### 커밋 후 읽기 구현

가장 흔한 방법 : 로우 수준 잠금 사용 -> 더티 쓰기 방지
트랜잭션에서 특정 객체를 변경하고 싶다면 먼저 해당 객체에 대한 잠금을 획득해야 한다.
트랜잭션이 커밋되거나 어보트될 때까지 잠금을 보유하고 있어야 한다.
쓰여진 모든 객체에 대해 데이터베이스는 과거에 커밋된 값과 현재 쓰기 잠금을 갖고 있는 트랜잭션에서 쓴 새로운 값을 모두 기억한다.
해당 트랜잭션이 실행 중인 동안 그 객체를 읽는 다른 트랜잭션들은 과거의 값을 읽게 된다.
새 값이 커밋되어야함 다른 트랜잭션들이 새 값을 읽을 수 있게 된다.

### 스냅숏 격리와 반복 읽기

커밋 후 읽기 격리는 피상적으로 보면 트랜잭션이 해야 하는 모든 일을 해 주는 것으로 생각해도 무리가 아니다

1. 어보트를 허용하고,
2. 트랜잭션의 미완료된 결과를 읽는 것을 방지하고,
3. 동시에 실행되는 쓰기가 섞이는 것을 막아준다.

하지만, 커밋 후 읽기 격리 수준을 사용하더라도 동시성 버그가 생길 수 있는 경우가 아직 많이 존재.
-> NonRepeatable Read (비반복 읽기) 나 읽기 스큐(Read Skew)
: 조회 시 이전 질의에서 봤던 것과 다른 값을 보게 되는 현상
위 현상은 커밋 후 읽기 격리에서는 받아들일 수 있는 것으로 여겨진다.
또한, 지속적인 문제는 아니다.

스냅숏 격리는 이런 문제의 가장 흔한 해결책이다.

- 각 트랜잭션은 데이터베이스의 일관된 스냅숏으로부터 읽는다.
  -> 트랜잭션은 시작할 때 데이터베이스에 커밋된 상태였던 모든 데이터를 본다.
- 데이터가 나중에 다른 트랜잭션에 의해 바뀌더라도 각 트랜잭션은 특정한 시점의 과거 데이터를 볼 뿐이다.
- 백업이나 분석처럼 실행하는 데 오래 걸리며 읽기만 실행하는 질의에 요긴함

: 트랜잭션이 특정 시점에 고정된 데이터베이스의 일관된 스냅숏만 볼 수 있다고 이해하면 편함

#### 스냅숏 격리 구현

스냅숏 격리 구현은 커밋 후 읽기 격리처럼 전형적으로 더티 쓰기를 방지하기 위해 쓰기 잠금을 사용한다.
하지만, 읽을 때는 아무 잠금도 필요 없다.

스냅숏 격리의 핵심 원리
: 읽는 쪽에서 쓰는 쪽을 결코 차단하지 않고 쓰는 쪽에서 읽는 쪽을 결코 차단하지 않는다.

데이터베이스는 객체마다 커밋된 버전 여러 개를 유지
-> 진행 중인 여러 트랜잭션에서 서로 다른 시점의 데이터베이스 상태를 봐야할 수도 있기 때문
-> 다중 버전 동시성 제어 (MVCC, Multi-Version Concurrency Control)

데이터베이스가 스냅숏 격리가 아니라 커밋 후 읽기 격리만 제공할 필요가 있다면 객체마다 버전 2개씩만 유지하면 된다.
-> 커밋된 버전과 덮어 쓰여졌지만 아직 커밋되지 않은 버전

- 커밋 후 읽기 : 질의마다 독립된 스냅숏을 사용
- 스냅숏 격리 : 전체 트랜잭션에 대해 동일한 스냅숏을 사용

MVCC 기반 스냅숏 격리 구현

- 트랜잭션이 시작하면 계속 증가하는 고유한 트랜잭션 ID를 할당받는다.
- 테이블의 각 로우에는 그 로우를 테이블에 삽입한 트랜잭션의 ID를 갖는 created_by 필드
- 각 로우에는 처음에는 비어있는 deleted_by 필드 : 트랜잭션이 로우를 삭제하면 실제로 데이터베이스에서 지우지 않고 deleted_by 필드를 삭제 요청 트랜잭션의 ID로 설정함으로써 지워졌다고 표시
- 나중에 아무 트랜잭션도 더 이상 삭제된 데이터에 접근하지 않는게 확실 -> 데이터베이스의 가비지 컬렉션 프로세스가 지워졌다고 표시된 로우들을 삭제하여 사용량 줄임

#### 일관된 스냅숏을 보는 가시성 규칙

트랜잭션은 데이터베이스에서 객체를 읽을 때 트랜잭션 ID를 사용해 어떤 것을 볼 수 있고 어떤 것을 볼 수 없는지를 결정.

1. 각 트랜잭션을 시작할 때 그 시점에 진행 중인 모든 트랜잭션의 목록을 만든다.
   -> 이 트랜잭션이 쓴 데이터는 무시된다.
2. 어보트된 트랜잭션이 쓴 데이터는 모두 무시된다.
3. 트랜잭션 ID가 더 큰 트랜잭션이 쓴 데이터는 모두 무시된다.
4. 그 밖의 모든 데이터는 애플리케이션의 질의로 볼 수 있다.

바꿔말하면, 아래 두 조건이 모두 참이면 객체를 볼 수 있다.

- 읽기를 실행하는 트랜잭션이 시작하는 시점에 읽기 대상 객체를 생성한 트랜잭션이 이미 커밋된 상태
- 읽기 대상 객체가 삭제된 것으로 표시되지 않았다. 또는 삭제된 것으로 표시됐지만 읽기를 실행한 트랜잭션이 시작한 시점에 삭제 요청 트랜잭션이 아직 커밋되지 않았다.

데이터베이스는 갱신할 때 값을 교체 X -> 새 버전을 생성 -> 작은 오버헤드만 유발 & 일관된 스냅숏 제공

#### 색인과 스냅숏 격리

MVCC 데이터베이스에서 색인 동작 방식
하나의 선택지 : 단순하게 색인이 객체의 모든 버전을 가리키게 하고 색인 질의가 현재 트랜잭션에서 볼 수 없는 버전을 걸러내게 하는 것
가비지 컬렉션이 어떤 트랜잭션에게도 더 이상 보이지 않는 오래된 객체 버전을 삭제할 때 대응되는 색인 항목도 삭제

#### 반복 읽기와 혼란스러운 이름

스냅숏 격리는 유용한 격리 수준이며 특히 읽기 전용 트랜잭션에 유용
Oracle에서는 직렬성, MySQL에서는 Repeatable Read라 칭함

이름이 혼란스러운 이유 : SQL 표준에 스냅숏 격리의 개념이 없기 때문

### 갱신 손실 방지

갱신 손실(Lost update) : 동시에 실행되는 쓰기 트랜잭션 사이에 발생할 수 있는 흥미로운 종류의 충돌 중 1가지

- 애플리케이션이 데이터베이스에서 값을 읽고 변경한 후 변경된 값을 다시 쓸 때 발생
- 만약 두 트랜잭션이 이 작업을 동시에 하면 두 번째 쓰기 작업이 첫 번째 변경을 포함하지 않으므로 변경 중 하나는 손실 가능

#### 원자적 쓰기 연산

원자적 갱신 연산 : 애플리케이션 코드에서 read-modify-write 주기를 구현할 필요를 없애줌
`UPDATE counters SET value = value + 1 WHERE key = 'foo';`
: 대부분의 관계형 데이터베이스에서 동시성 안전한 명령어

원자적 연산은 객체를 읽을 때 그 객체에 독점적인 잠금을 획득해서 구현한다.
갱신이 적용될 때까지 다른 트랜잭션에서 그 객체를 읽지 못한다.
-> 커서 안정성
다른 선택지 : 모든 원자적 연산을 단일 스레드에서 실행되도록 강제하는 것

주의. 객체 관계형 매핑 프레임워크를 사용하면 뜻하지 않게 데이터베이스가 제공하는 원자적 연산을 사용하는 대신 불안전한 read-modify-write 주기를 실행하는 코드를 작성하기 쉽다.

#### 명시적인 잠금

데이터베이스에 내장된 원자적 연산이 필요한 기능을 제공하지 않을 때 갱신 손실을 막는 또 다른 선택지
: 애플리케이션에서 갱신할 객체를 명시적으로 잠그는 것
-> 애플리케이션이 read-modify-write 주기를 수행할 수 있고, 다른 트랜잭션이 동시에 같은 객체를 읽으려 하면 첫 번째 주기가 완료될 때까지 기다리도록 강제됨

`SELECT * FROM figures WHERE name = 'robot' AND game_id = 222 FOR UPDATE`
FOR UPDATE : 데이터베이스가 이 질의에 의해 반환된 모든 로우에 잠금을 획득해야 함

### 갱신 손실 자동 감지

원자적 연산과 잠금은 read-modify-write 주기가 순차적으로 실행되도록 강제 -> 갱신 손실을 방지하는 방법
대안 : 병렬 실행을 허용, 트랜잭션 고나리자가 갱신 손실을 발견하면 트랜잭션을 어보트시키고 read-modify-write 주기를 재시도하도록 강제하는 방법
대안의 이점 : 데이터베이스가 이 확인을 스냅숏 격리와 결합해 효율적으로 수행할 수 있음
실제로, PostgreSQL의 반복 읽기, Oracle의 직렬성, SQL Server의 스냅숏 격리 수준은 갱신 손실이 발생하면 자동으로 발견해서 문제가 되는 트랜잭션을 어보트시킨다.
하지만, MySQL의 반복 읽기는 갱신 손실을 감지하지 않는다.

#### Compare-and-set

트랜잭션을 제공하지 않는 데이터베이스 중에는 원자적 Compare-and-set 연산을 제공하는 것도 존재.
이 연산의 목적 : 값을 마지막으로 읽은 후로 변경되지 않았을 때만 갱신을 허용 -> 갱신 손실 회피
현재 값이 이전에 읽은 값과 일치하지 않으면 갱신은 반영되지 않음
-> read-modify-write 주기를 재시도해야 함

### 충돌 해소와 복제

복제가 적용된 데이터베이스에서 갱신 손실을 막는 것은 다른 차원의 문제
데이터가 다른 노드들에서 동시에 변경될 수 있음 -> 갱신 손실 방지를 위해서는 추가 단계 필요
잠금과 compare-and-set 연산은 데이터의 최신 복사본이 하나만 있다고 가정한다.
다중 리더 또는 리더 없는 복제를 사용하는 데이터베이스는

1. 여러 쓰기가 동시에 실행
2. 비동기식으로 복제되는 것을 허용
   -> 데이터의 최신 복사본이 하나만 있으리라고 보장할 수 없음
   -> 잠금과 compare-and-set을 기반으로 한 기법을 적용할 수 없음

복제가 적용된 데이터베이스에서 흔히 쓰는 방법

1. 쓰기가 동시에 실행될 때
2. 한 값에 대해 여러 개의 충돌된 버전(형제, Sibling)을 생성하는 것을 허용
3. 차후에 애플리케이션 코드나 특별한 데이터 구조를 사용해 충돌을 해소
4. 이 버전들을 병합

원자적 연산은 복제 상황에서도 잘 동작한다.

### 쓰기 스큐와 팬텀

다른 트랜잭션들이 동시에 같은 객체에 쓰려고 할 때 발생할 수 있는 두 가지 경쟁 조건

1. 더티 쓰기 : 뒤에 발생한 트랜잭션이 아직 커밋되지 않은 값을 덮어써버리는 것
2. 갱신 손실 : 두 트랜잭션 중 한 개의 트랜잭션에서 커밋된 값이 손실되는 것

#### 쓰기 스큐를 특징짓기

두 트랜잭션이 두 개의 다른 객체를 갱신하였고 이로 인해 요구사항 위반이 발생
-> 쓰기 스큐

### 쓰기 스큐를 유발하는 팬텀

팬텀 : 어떤 트랜잭션에서 실행한 쓰기가 다른 트랜잭션의 검색 질의 결과를 바꾸는 효과
스냅숏 격리는 읽기 전용 질의에서 팬텀을 회피하지만 읽기 쓰기 트랜잭션에서는 팬텀이 쓰기 스큐의 특히 까다로운 경우를 유발할 수 있음

## 직렬성

직렬성 격리 : 보통 가장 강력한 격리 수준
-> 여러 트랜잭션이 병렬로 실행되더라도 최종 결과는 동시성 없이 한 번에 하나씩 직렬로 실행될 때와 같도록 보장
-> 데이터베이스가 발생할 수 있는 모든 경쟁 조건을 막아준다

오늘날 직렬성을 제공하는 데이터베이스는 대부분 세 가지 기법 중 하나를 사용한다

1. 말 그대로 트랜잭션을 순차적으로 실행하기
2. 수십 년 동안 유일한 수단이었던 2단계 잠금
3. 직렬성 스냅숏 격리 같은 낙관적 동시성 제어 기법

### 실제적인 직렬 실행

동시성 문제를 회피하는 가장 간단한 방법
: 동시성을 완전히 제거하는 것

#### 트랜잭션을 스토어트 프로시저 안에 캡슐화하기

데이터베이스 초창기 : 데이터베이스 트랜잭션이 사용자 활동의 전체 흐름을 포함할 수 있게 하려는 의도 존재
-> 전체 과정이 하나의 트랜잭션으로 표현되고 원자적으로 커밋될 수 있다면 깔끔할 것!
하지만 사람은 결정하는 것도 반응하는 것도 매우 느리다
-> 데이터베이스 트랜잭션이 사용자의 입력을 기다려야 한다면 데이터베이스는 대부분 유휴 상태지만 잠재적을 매우 많은 동시 실행 트랜잭션을 지원해야 한다
-> 효율적 처리 불가능, 거의 모든 OLTP 애플리케이션은 트랜잭션 내에서 대화식으로 사용자 응답을 대기하는 것을 회피
-> 트랜잭션을 짧게 유지
: 웹의 경우 트랜잭션이 동일한 HTTP 요청 내에서 커밋된다는 뜻

상호작용식 트랜잭션 : 애플리케이션과 데이터베이스 사이의 네트워크 통신에 많은 시간을 소비
데이터베이스에서 동시성을 허용하지 않고 한 번에 트랜잭션 하나씩만 처리하면 처리량은 끔찍할 것
단일 스레드에서 트랜잭션을 순차적으로 처리하는 시스템들은 상호작용하는 다중 구문 트랜잭션을 허용하지 않는다.
대신 애플리케이션은 트랜잭션 코드 전체를 스토어드 프로시저 형태로 데이터베이스에 미리 제출해야 한다

# 4장. 분산 메시지 큐

분산 메시지 큐 사용 시 이점

- 결합도 완화 : 강결합 사라짐
- 규모 확장성 개선 : 생산자와 소비자가 독립적
- 가용성 개선 : 개별 컴포넌트의 장애와 상관없이 다른 컴포넌트는 큐와 상호작용
- 성능 개선 : 비동기 통신 가능

## 기능 요구사항

- 생산자는 메시지 큐에 메시지를 보낼 수 있어야 한다.
- 소비자는 메시지 큐를 통해 메시지를 수신할 수 있어야 한다.
- 메시지는 반복적으로 수신 or 단 한 번만 수신하도록 설정
- 오래된 이력 데이터 삭제될 수 있다.
- 메시지 크기는 킬로바이트 수준
- 메시지는 생산된 순서대로 소비자에게 전달
- 메시지 전달 방식은 최소 한 번, 최대 한 번, 정확히 한 번 가운데 설정할 수 있어야 한다.

## 비기능 요구사항

- 높은 대역폭과 낮은 전송 지연 가운데 하나를 설정할 수 있어야 하는 기능
- 규모 확장성, 메시지 양이 급증해도 처리 가능해야 함
- 지속성 및 내구성, 데이터는 디스크에 지속적으로 보관 & 여러 노드에 복제되어야 함

### 전통적 메시지 큐와 다른 점

전통적 메시지 큐 : 메시지 보관 문제 중요 X
-> 메시지가 소비자에게 전달되기 충분한 기간동안만 메모리에 보관
메시지 전달 순서도 보존 X
-> 생산된 순서와 소비되는 순서 다를 수 있음

## 메시지 모델

### 일대일 (point to point)

- 전통적인 메시지 큐에서 흔히 발견되는 모델
- 오직 한 소비자만 메시지를 소비
- 데이터 보관 (Data Retention) 지원 X

과정

1. 소비지가 메시지 가져감
2. 소비자가 큐에 알림 (Acknowledge)
3. 메시지 큐에서 삭제

### 발행-구독 (publish-subscribe)

토픽 : 메시지를 주제별로 정리하는 데 사용
각 토픽은 메시지 큐 서비스 전반에 고유한 이름을 가짐

토픽에 전달된 메시지는 해당 토픽을 구독하는 모든 소비자에게 전달

#### 토픽, 파티션, 브로커

토픽에 보관되는 데이터의 양이 커져서 서버 한 대로 감당이 어려움
-> 파티션 사용으로 해결 가능
토픽을 여러 파티션으로 분할한 다음, 메시지를 모든 파티션에 균등하게 나눠 보냄
-> 파티션 : 토픽에 보낼 메시지의 작은 부분 집합

파티션은 메시지 큐 클러스터 내의 서버에 고르게 분산 배치함
파티션을 유지하는 서버 -> 브로커
파티션을 브로커에 분산하는 것이 높은 규모 확장성을 달성하는 비결
토픽의 용량을 확장하고 싶으면 파티션 개수를 늘리면 됨

각 토픽 파티션은 FIFO로 동작
-> 같은 파티션 안에서는 메시지 순서가 유지됨

생산자가 보낸 메시지는 해당 토픽의 파티션 중 하나로 보내짐

- 같은 키를 가진 모든 메시지는 같은 파티션으로 보내짐
- 키가 없는 메시지는 랜덤한 파티션으로 보내짐

토픽을 구독하는 소비자는 하나 이상의 파티션에서 데이터를 가져오게 된다.
-> 소비자가 파티션보다 많으면 유휴 소비자 발생 가능

#### 소비자 그룹

하나의 소비자 그룹은 여러 토픽 구독 & 오프셋을 별도로 관리
같은 그룹 내의 소비자는 메시지를 병렬로 소비 가능
-> 병렬로 소비 시 대역폭 좋음, 하지만 같은 파티션 안에 있는 메시지를 순서대로 소비 불가능
-> 소비 순서 보장 불가능

소비 순서 보장 방법
: 어떤 파티션의 메시지는 한 그룹 안에서는 오직 한 소비자만 읽을 수 있도록 강제
-> 그룹 내 소비자 수가 구독하는 토픽의 파티션 수보다 많으면 유휴 소비자 발생

## 개략적 설계안

클라이언트

- 생산자 : 메시지를 특정 토픽으로 보낸다
- 소비자 그룹 : 토픽을 구독하고 메시지를 소비한다

핵심 서비스 및 저장소

- 브로커 : 파티션들을 유지, 하나의 파티션은 특정 토픽에 대한 메시지의 부분 집합을 유지
- 데이터 저장소 : 메시지는 파티션 내 데이터 저장소에 보관
- 상태 저장소 : 소비자 상태 저장
- 메타데이터 저장소 : 토픽 설정, 토픽 속성 등 저장
- 조정 서비스
  - 서비스 탐색 (Service Discovery) : 어느 브로커가 살아있는지
  - 리더 선출 : 브로커 가운데 하나는 컨트롤러 역할을 담당. 한 클러스터에는 반드시 활성 상태의 컨트롤러가 1개는 존재해야함. 파티션 배치를 책임

## 상세 설계

데이터 장기 보관 및 높은 대역폭 제공을 위한 3가지 결정

- 디스크 기반 자료구조 활용
- 메시지가 생산자 -> 소비자에게 전달되는 순간까지 아무 수정 없이 전송 가능한 메시지 자료구조
- 일괄 처리를 우선하는 시스템 설계, 소규모 I/O 많으면 높은 대역폭 지원 어려움.
  생산자는 메시지 일괄 전송, 메시지 큐는 그 메시지들을 더 큰 단위로 묶어 보관, 소비자도 가능하면 메시지 일괄 수신

### 데이터 저장소

메시지 큐의 트래픽 패턴

- 읽기와 쓰기가 빈번하게 발생
- 갱신/삭제 연산은 발생 X
- 순차적인 읽기/쓰기가 대부분

WAL (Write Ahead Log), 쓰기 우선 로그
: 새로운 항목이 추가되기만 하는 append-only 일반 파일
MySQL의 복구 로그 (redo log), 아파치 주키퍼에서도 활용

지속성을 보장해야 하는 메시지는 디스크에 WAL로 보관할 것을 추천
WAL의 접근 패턴 : 읽기/쓰기 전부 순차적
-> 접근 패턴이 순차적일때 디스크는 아주 좋은 성능을 보임

새로운 메시지는 파티션 꼬리 부분에 추가, 오프셋은 그 결과로 점진적으로 증가
세그먼트 단위로 관리.
비활성 세그먼트 파일은 보관 기한이 만료되거나 용량 한계에 도달하면 삭제

#### 디스크 성능 관련 유의사항

데이터 장기 보관에 대한 요구사항으로 인해 디스크 드라이브 활용하여 대량의 데이터 보관
회전식 디스크가 느린 것은 데이터 접근 패턴이 무작위일 때.
메시지 큐에서는 데이터 접근 패턴이 순차적이므로 충분히 적합한 성능 발휘.

현대적 운영체제는 디스크 데이터를 메모리에 아주 적극적으로 캐시
-> WAL도 OS가 제공하는 디스크 캐시 기능을 적극적으로 활용

### 메시지 자료 구조

메시지 자료구조는 높은 대역폭 달성의 열쇠
메시지가 큐를 거쳐 소비자에게 전달되는 과정에서 불필요한 복사가 일어나지 않도록 해야 높은 대역폭 달성 가능

필드 이름 : 데이터 자료형

- key : byte[]
- value : byte[]
- topic : string
- partition : integer
- offset : long
- timestamp : long
- size : integer
- crc : integer

#### 메시지 키

파티션을 정할 때 사용

- 키가 주어지지 않은 메시지는 파티션이 무작위로 결정
- 키가 주어진 메시지는 파티션이 hash(key) % numPartitions 공식에 따라 결정

더 유연한 설계가 필요하다면 생산자는 직접 파티션 선정 메커니즘을 정의 가능

키에는 비즈니스 관련 정보가 담기는 것이 보통

#### 메시지 값

메시지의 내용, 즉 payload

#### 메시지의 기타 필드

- 토픽 : 메시지가 속한 토픽의 이름
- 파티션 : 메시지가 속한 파티션의 ID
- 오프셋 : 파티션 내의 메시지의 위치. 메시지는 토픽, 파티션, 오프셋 세 가지 정보를 알면 찾을 수 있다.
- 타임스탬프 : 메시지가 저장된 시각
- 크기 : 메시지의 크기
- CRC : 순환 중복 검사, 주어진 데이터의 무결성을 보장하는데 이용

### 일괄 처리

일괄처리 : 시스템 성능에 아주 중요

이유

- 운영체제로 하여금 여러 메시지를 한 번의 네트워크 요청으로 전송할 수 있도록 하기 때문에 값비싼 네트워크 왕복 비용 제거 가능
- 브로커가 여러 메시지를 한 번에 로그에 기록하면 더 큰 규모의 순차 쓰기 연산이 발생 -> 디스크 캐시에서 더 큰 규모의 연속된 공간을 점유 가능

높은 대역폭과 낮은 응답 지연은 동시에 달성하기 어려운 목표
시스템이 낮은 응답 지연이 중요한 전툥적 메시지 큐로 이용된다면 일괄 처리 메시지 양은 낮춘다.
-> 디스크 성능은 다소 낮아진다

처리량을 높여야 한다면 토픽당 파티션의 수를 늘린다
-> 낮아진 순차 쓰기 연산 대역폭을 발충할 수 있다

### 생산자 측 작업 흐름

생산자가 어떤 파티션에 메시지를 보내야할 때 어느 브로커에 연결해야 할까?
-> 해결책 : 라우팅 계층
라우팅 계층이 적절한 브로커에 메시지를 보내는 역할을 담당
메시지를 받을 적절한 브로커 : 리더 브로커

생산자 내부에 라우팅 계층을 두고 버퍼를 도입
생산자 클라이언트 라이브러리의 일부로 생산자에 설치
-> 생산자에서 라우팅 계층으로의 네트워크를 거칠 필요가 없으므로 전송 지연 감소
-> 생산자는 메시지를 어느 파티션에 보낼지 결정하는 자신만의 로직을 가질 수 있음
-> 저송할 메시지를 버퍼 메모리에 보관했다가 목적지로 일괄 전송하여 대역폭을 높일 수 있음

- 일괄 처리 메시지의 양을 늘리면 대역폭 증가 but 응답 속도 느려짐
  :일괄 처리가 가능할 양의 메시지를 기다려야 함
- 양을 줄이면 메시지는 더 빨리 보낼 수 있으니 지연은 줄어들지만 대역폭 손해

생산자는 메시지 큐의 용도를 감안하여 일괄 처리 메시지 양을 조정해야 함

### 소비자 측 작업 흐름

소비자는 특정 파티션의 오프셋을 주고 해당 위치에서부터 이벤트를 묶어 가져온다

#### 푸쉬 vs 풀

푸쉬 모델

- 장점
  - 낮은 지연 : 브로커는 메시지를 받는 즉시 소비자에게 보낼 수 있다.
- 단점
  - 소비자의 메시지 처리 속도보다 생신자의 메시지 생산 속도가 빠를 경우, 소비자에게 큰 부하 발생
  - 생산자가 데이터 전송 속도를 좌우하므로, 소비자의 컴퓨팅 자원은 생산자에 의존적으로 준비 필요

풀 모델

- 장점
  - 메시지 소비 속도를 소비자가 알아서 결정
  - 메시지 소비 속도가 생산 속도보다 느려지면 소비자를 늘려 해결하거나 생산 속도를 따라잡을 때까지 기다릴 수도 있음
  - 일괄 처리에 적합. 소비자가 지난번 마지막으로 가져간 로그 위치 다음에 오는 모든 메시지를 한 번에 가져갈 수 있음. 공격적 일괄 처리에 좀 더 적합
- 단점
  - 브로커에 메시지가 없어도 소비자는 계속 데이터를 끌어가려 시도, 소비자 측 컴퓨팅 자원이 낭비됨. 롱 폴링 모드로 극복 (당장은 가져갈 메시지가 없더라도 일정 시간은 기다리도록 하는 것)

동작 흐름

1. 토픽 구독을 원하는 새로운 소비자 등장. 그룹 이름을 해싱하여 접속할 브로커 노드를 찾음. 같은 그룹의 모든 소비자는 같은 브로커에 접속. 해당 브로커는 해당 소비자 그룹의 코디네이터. 코디네이터는 소비자 그룹의 조정 작업만 담당
2. 코디네이터는 해당 소비자를 그룹에 참여시키고 해당 소비자에게 파티션을 할당
3. 소비자는 마지막으로 소비한 오프셋 이후 메시지를 가져온다. 오프셋 정보는 상태 저장소에 존재
4. 소비자는 메시지를 처리하고 새로운 오프셋을 브로커에 보낸다. 데이터 처리와 오프셋 갱신 순서는 메시지 전송 시맨틱에 영향을 미침

### 소비자 재조정

어떤 소비자가 어떤 파티션을 책임지는지 다시 정하는 프로세스

- 새로운 소비자의 합류
- 기존 소비자의 이탈
- 특정 소비자의 장애 발생
- 파티션 조정
  위 경우에 소비자 재조정 프로세스 시작

소비자 재조정에는 코디네이터가 중요한 역할을 함
코디네이터 : 소비자 재조정을 위해 소비자들과 통신하는 브로커 노드
소비자로부터 오는 하트비트 메시지를 살피고 각 소비자의 파티션 내 오프셋 정보를 관리

- 같은 그룹의 모든 소비자는 같은 코디네이터에 연결
- 코디네이터는 자신에 연결한 소비자 목록을 유지. 이 목록에 변화가 생기면 코디네이터는 해당 그룹의 새 리더를 선출
- 새 리더는 새 파티션 배치 계획을 만들고 코디네이터에게 전달. 코디네이터는 해당 계획을 그룹 내 다른 모든 소비자에게 알림

소비자 장애 감지 시 코디네이터는 재조정 프로세스를 시작하여 파티션을 재배치함

#### 재조정 시나리오

코디네이터는 소비자 재조정이 필요할 시 모든 소비자에게 그 사실을 수동적으로 통지
-> 소비자의 하트비트 메시지가 왔을 때 그 응답으로 그룹에 다시 합류하라고 알림

모든 소비자의 그룹 합류 이후 리더 선출, 그룹 동기화 요청, 리더로부터 받은 파티션 배치 계획 전파

### 상태 저장소

- 소비자에 대한 파티션의 배치 관계
- 각 소비자 그룹이 각 파티션에서 마지막으로 가져간 메시지의 오프셋
  를 저장한다.

소비자 상태 정보 데이터가 이용되는 패턴

- 읽기와 쓰기가 빈번하게 발생, 양은 많지 않음
- 데이터 갱신은 빈번하게 일어나지만 삭제되는 일은 거의 없음
- 읽기와 쓰기 연산은 무작위적 패턴
- 데이터의 일관성이 중요

-> 아파치 주키퍼와 같은 키-값 저장소 사용이 바람직

### 메타데이터 저장소

토픽 설정이나 속성 정보를 보관
(파티션 수, 메시지 보관 기간, 사본 배치 정보 등)

메타데이터는 자주 변경되지 않으며 양도 적다. 하지만 높은 일관성을 요구
-> 주키퍼가 적절

#### 주키퍼

계층적 키-값 저장소
-> 분산 시스템에 필수적인 서비스

- 메타데이터와 상태 저장소는 주키퍼를 이용해 구현
- 브로커는 이제 메시지 데이터 저장소만 유지
- 주키퍼가 브로커 클러스터의 리더 선출 과정을 돕는다

### 복제

분산 시스템에서 하드웨어 장애는 흔한 일, 디스크에 손상이나 영구적 장애 발생 시 데이터 유실
-> 높은 가용성 보장을 위해 복제 사용

사본들은 서로 다른 브로커 노드에 분산
생산자는 파티션에 메시지를 보낼 때 리더에게만 보냄
다른 사본은 리더에서 새 메시지를 지속적으로 가져와 동기화
메시지를 완전히 동기화한 사본의 개수가 지정된 임계값을 넘으면 리더는 생산자에게 메시지를 잘 받았다는 응답을 보냄

사본 분산 계획 : 사본을 파티션에 어떻게 분산할지 기술하는 것
-> 조정 서비스의 도움으로 브로커 노드 중 하나가 리더로 선출되면 해당 리더 브로커 노드가 사본 분산 계획을 만들고 메타데이터 저장소에 보관

#### 사본 동기화

어떤 한 노드의 장애로 메시지가 소실되는 것을 막기 우해 메시지는 여러 파티션에 두며 각 파티션은 다시 여러 사본으로 복제
-> 문제는 그 모두를 어떻게 동기화시킬 것인지
동기화된 사본 : In-Sync Replicas, ISR은 리더와 동기화된 사본

리더와 사본의 합의된 오프셋까지 동기화되었다면 해당 사본은 ISR.
ISR이 필요한 이유 : 성능과 영속성 사이의 타협점
생산자가 보낸 어떤 메시지도 소실하지 않는 가장 안전한 방법
: 생산자에게 메시지를 잘 받았다는 응답을 보내기 전에 모든 사본을 동기화하는 것
-> 어느 사본 하나라도 동기화를 신속하게 처리하지 못한다면 파티션 전부가 느려지거나 아예 못 쓰게 되는 일 발생

#### ACK=all

생산자는 모든 ISR이 메시지를 수신한 뒤에 ACK 응답을 받는다.
느린 ISR의 응답을 기다려야 하므로 메시지를 보내기 위한 시간이 길어진다.
메시지의 영속성 측면에서는 가장 좋은 구성

#### ACK=1

생산자는 리더가 메시지를 저장하고 나면 바로 ACK 응답을 받는다
데이터가 동기화될 때까지 기다리지 않아서 응답 지연은 개선된다.
메시지 ACK를 보낸 직후 리더에 장애가 생기면 해당 메시지는 다른 사본에 반영되지 못했으므로 영구 소실됨
데이터가 사라져도 상관없는 대신 낮은 응답 지연을 보장해야 하는 시스템에 적합

#### ACK=0

생산자는 보낸 메시지에 대한 수신 확인 메시지를 기다리지 않고 계속 메시지 전송하며 어떤 재시도도 하지 않음
지표 수집이나 데이터 로깅 등 처리해야 하는 메시지의 양이 많고 때로 데이터 손실이 발생해도 상관 없는 경우에 좋다.

ACK 설정이 변경 가능하면 성능을 높여야 할 경우 영속성을 다소 희생할 수도 있다.

소비자 측에서는 가장 쉬운 구성은 소비자로 하여금 리더에게 메시지를 읽어가도록 하는 것

리더 사본에 요청이 너무 몰리거나 ISR 요건을 만족하는 사본에서 메시지를 가져가지 않는 이유

- 설계 및 운영이 단순
- 특정 파티션의 메시지는 같은 소비자 그룹 안에서는 오직 한 소비자만 읽어갈 수 있으므로 리더 사본에 대한 연결은 많지 않음
- 아주 인기 있는 토픽이 아니라면 리더 사본에 대한 연결의 수는 그렇게 많지 않음
- 아주 인기 있는 토픽의 경우 파티션 및 소비자 수를 늘려 규모 확장 가능

어떤 사본이 ISR인지 아닌지 판단
-> 각 파티션 담당 리더는 자기 사본들이 어느 메시지까지 가져갔는지 추적하여 ISR 목록 관리

### 규모 확장성

- 생산자
  - 새로운 생산자를 추가하거나 삭제
- 소비자
  - 소비자 그룹은 서로 독립적, 새 소비자 그룹은 쉽게 추가 및 삭제 가능
  - 같은 소비자 그룹 내의 소비자가 새로 추가/삭제되거나 장애로 제거되어야 하는 경우 재조정 메커니즘이 맡아 처리
  - 소비자 측의 규모 확장성과 결함 내성을 보장하는 것 : 소비자 그룹 & 재조정 메커니즘
- 브로커
  - 가장 간단한 해법 : 브로커 노드가 추가되거나 삭제될 때 사본을 재배치
  - 더 나은 방법 : 브로커 컨트롤러로 하여금 한시적으로 시스템에 설정된 사본 수보다 많은 사본을 허용하도록 하는 것. 새로 추가된 브로커 노드가 기존 브로커 상태를 따라잡고 나면 더 이상 필요 없는 노드를 제거
- 파티션
  - 파티션 수 조정 시 생산자와 소비자의 안전성에는 영향 X
    - 생산자는 브로커와 통신할 때 그 사실을 통지 받음
    - 소비자는 재조정 시행
  - 파티션 수가 달리지면 데이터 저장 계층에 발생하는 일
    - 파티션 추가
      - 지속적으로 보관된 메시지는 여전히 기존 파티션에 존재, 이동 X
      - 새로운 파티션이 추가되면 그 이후 메시지는 파티션 전부에 지속적으로 보관
    - 파티션 제거
      - 새로운 메시지는 퇴역시키지 않을 파티션에만 보관
      - 퇴역된 파티션은 바로 제거하지 않고 일정 시간 동안 유지 (해당 파티션의 데이터를 읽고 있는 소비자가 있을 수 있기 대문, 해당 유지 기간이 지나고 데이터 삭제 후 저장 공간 반환)
      - 파티션 퇴역 후 실제로 제거가 이루어지는 시점까지 생산자는 메시지를 다른 파티션으로만 보내지만 소비자는 파티션 모두에서 메시지를 읽는다. 실제로 파티션이 제거되는 시점이 오면 소비자 그룹은 재조정 작업을 개시해야 한다.

### 메시지 전달 방식

#### At-most once, 최대 한 번

메시지 전달 과정에서 소실되더라고 다시 전달되는 일은 없다.

- 생산자는 토픽에 비동기적으로 메시지 보내고 수신 응답을 기다리지 않는다. (ACK=0)
- 소비자는 메시지를 읽고 처리하기전에 오프셋부터 갱신

지표 모니터링 등 소량의 데이터 손실은 감수할 수 있는 애플리케이션에 적합

#### At-least once, 최소 한 번

같은 메시지가 한 번 이상 전달될 수는 있으나 메시지 소실은 발생하지 않는 전달 방식

- 생산자는 메시지를 동기적/비동기적으로 보낼 수 있으며 ACK=1 또는 ACK=all 구성을 이용. 메시지가 브로커에게 전달되었음을 반드시 확인. 메시지 전달이 실패하거나 타임아웃이 발생하면 계속 재시도
- 소비자는 데이터를 성공적으로 처리한 뒤에만 오프셋을 갱신. 메시지 처리 실패한 경우 메시지를 다시 가져오므로 데이터가 손실되는 일은 없음. 메시지 중복 처리 발생 가능

메시지가 소실되는 일은 없지만 같은 메시지가 여러 번 전송될 수 있다.
데이터 중복이 큰 문제가 아닌 애플리케이션이나 소비자가 중복을 직접 제거할 수 있는 애플리케이션의 경우에는 충분히 괜찮은 전송 방식
(메시지마다 고유한 키가 있고 해당 키가 이미 데이터베이스에 있는 메시지는 처리하지 않고 버리거나..)

#### exactly once, 정확히 한 번

구현하기 가장 까다로운 전송 방식. 시스템의 성능 및 구현 복잡도 측면에서 큰 대가 지불 필요
지불, 매매, 회계 등 금융 관련 응용에는 이 전송 방식이 적합

### 메시지 필터링

메시지를 필터링하는 가장 쉬운 방법 : 소비자가 일단 모든 메시지를 받은 다음 필요 없는 메시지는 버리는 방법.
-> 유연성 높은 방법, 불필요한 트래픽 발생하여 시스템 성능 저하 가능

더 나은 방법 : 브로커에서 메시지를 필터링하여 소비자는 원하는 메시지만 받을 수 있도록 하는 것
메시지마다 태그를 두어 소비자는 어떤 태그를 가진 메시지를 구독할지 지정

### 메시지 지연 전송 및 예약 전송

발송 즉시 전달되는 메시지와는 달리 이런 메시지는 토픽에 바로 저장하지 않고 브로커 내부의 임시 저장소에 넣어 두었다가 시간이 되면 토픽으로 옮긴다.

- 하나 이상의 특별 메시지 토픽을 임시 저장소로 활용할 수 있다.

# 7장. 호텔 예약 시스템

## 기능 요구사항

- 호텔 정보 페이지 표시
- 객실 정보 페이지 표시
- 객실 예약 지원
- 호텔이나 객실 정보를 추가/삭제/갱신하는 관리자 페이지 지원
- 초과 예약 지원

## 비기능 요구사항

- 높은 수준의 동시성 : 성수기, 대규모 이벤트 기간에 높은 트래픽이 몰릴 수 있음
- 적절한 지연 시간 : 예약에 대한 응답 시간이 빠르며 이상적이지만 예약 요청 처리에 몇 초 정도 걸리는 것은 괜찮음

## 개략적 설계

### API 설계

RESTful

- 호텔 관련 API (GET, POST, PUT, DELETE)
- 객실 관련 API (GET, POST, PUT, DELETE)
- 예약 관련 API (GET, POST, PUT, DELETE)
  - 중복 예약 방지 및 예약이 1번만 된다는 보증을 위한 멱등 키 필요 (idempotent key)

```
{
"startDate" : "2021-04-28",
"endDate" : "2021-04-30",
"hotelID":"245",
"roomID":"U12345673389",
"reservationID":"13422445"
}
```

### 데이터 모델

호텔 예약 시스템이 지원해야 하는 질의

- 호텔 상세 정보 확인
- 지정된 날짜 범위에 사용 가능한 객실 유형 확인
- 예약 정보 기록
- 예약 내역 또는 과거 예약 이력 정보 조회

관계형 데이터베이스가 적합.

- 읽기 빈도가 쓰기 빈도에 비해 높은 작업 흐름을 잘 지원
  - 호텔 웹사이트/앱을 방문하는 사용자의 수가 실제로 객실을 예약하는 사용자 수에 비해 압도적으로 많음.
  - NoSQL 데이터베이스는 대체로 쓰기 연산에 최적화.
- ACID, 예약 시스템을 만드는 경우 중요
- 데이터를 쉽게 모델링
  - 비즈니스 데이터의 구조를 명확하게 표현 가능.
  - 엔티티들의 관계를 안정적으로 지원 가능

예약 테이블에는 status 필드가 필요

- pending, paid, refunded, canceled, rejected

5가지 상태로 결제 대기, 결제 완료, 환불 완료, 취소, 승인 실패 표현

### 개략적 설계안

MSA(Micro Service Architecture) 사용

공개 API 게이트웨이
-> 각 서비스별로 라우팅
-> 각 서비스별로 별도의 DB 소유

## 상세 설계

### 개선된 데이터 모델

호텔 객실 예약 시 특정 객실이 아닌 특정한 객실 유형을 예약하게 된다.
-> roomID가 아닌 roomTypeID 필요

객실 유형에 대한 인벤토리 테이블 필요 (room_type_inventory)

- hotel_id : 호텔 식별자
- room_type_id : 객실 유형 식별자
- date : 일자
- total_inventory : 예약 가능한 총 객실 수
- total_reserved : 예약된 객실 수

이 테이블의 기본 키 : (hotel_id, room_type_id, date)
-> 복합 키
가용 객실 데이터 질의 결과를 토대로 미리 데이터를 채워 놓고, 시간의 흐름에 띠라 새로 추가해야 하는 객실 정보는 매일 한 번씩 일괄 작업으로 돌려 반영

room_type_inventory 테이블은 고객이 특정 유형의 객실을 예약할 수 있는지 여부를 확인할 때 사용
-> 2번의 프로세스로 진행

1. 주어진 기간에 해당하는 레코드들 조회
2. 반환된 각 레코드마다 현재 예약 가능한지 검사

만약, 예약 데이터가 단일 데이터베이스에 담기 너무 크다면?

- 현재 및 향후 예약 데이터만 저장. 예약 이력은 자주 접근하지 않으므로 아카이빙 또는 냉동 저장소로 옮김
- 데이터베이스 샤딩. 가장 자주 사용되는 질의는 예약을 하거나 투숙객 이름으로 예약 확인 질의 -> 두 질의 모두 호텔을 알아야 하므로, hotel_id 기반 샤딩

### 동시성 문제

중복 예약 가능성이 존재하는 2개의 문제

1. 같은 사용자가 예약 버튼을 여러 번 누름
2. 여러 사용자가 같은 객실을 동시에 예약

#### 같은 사용자의 이중 클릭

- 클라이언트 측 구현 : 클라이언트 단에서 이중 클릭에 대한 문제 방지. 대부분의 이중 클릭 문제는 해결되지만 안정적이진 않다. 악의적인 사용자는 이를 우회할 수 있다
- 멱등(idempotent) API : 예약 API 요청에 멱등 키를 추가하는 방안. 몇 번을 호출해도 동일한 결과는 내는 API = 멱등 API.

#### 다른 사용자의 동시 예약

해결방법 : 락

- 비관적 락
- 낙관적 락
- 데이터베이스 제약 조건 (constraint)

객실 예약 프로세스

1. 잔여 객실 확인
2. 객실 예약

##### 비관적 락

비관적 락 : 비관적 동시성 제어 방안
사용자가 레코드를 갱신하려는 순간 즉시 락을 걸어 동시 업데이트를 방지하는 기술
해당 레코드를 갱신하려는 다른 사용자는 먼저 락을 건 사용자가 변경을 마치고 락을 해제할 때까지 기다려야 한다.
ex) MySQL SELECT ... FOR UPDATE

장점

- 애플리케이션이 변경 중이거나 변경이 끝난 데이터를 갱신하는 일을 막는다.
- 구현이 쉽고 모든 갱신 연산을 직렬화하여 충돌을 막는다. 비관적 락은 데이터에 대한 경합이 심할 때 유용하다.

단점

- 여러 레코드에 락을 걸면 교착 상태가 발생할 수 있다.
- 확장성이 낮다. 트랜잭션이 너무 오랫동안 락을 해제하지 않고 있으면 다른 트랜잭션은 락이 걸린 자원에 접근할 수 없다. -> 트랜잭션의 수명이 길거나 많은 엔티티에 관련된 경우 데이터베이스 성능에 심각한 영향을 끼친다.

##### 낙관적 락

낙관적 락 : 낙관적 동시성 제어 방안
-> 여러 사용자가 동시에 같은 자원을 갱신하려 시도하는 것을 허용

구현 방식

1. 버전 번호
2. 타임스탬프

타임스탬프의 경우 서버 시계가 시간이 지남에 따라 부정확해질 수 있으므로 일반적으로 버전 번호를 더 나은 선택지로 본다.

버전 번호 구현 방식

1. 데이터베이스 테이블에 version이라는 새 열을 추가
2. 애플리케이션의 해당 레코드의 버전 번호를 읽음
3. 사용자가 레코드를 갱신할 때 애플리케이션은 버전 번호에 1을 더한 다음 데이터베이스에 기록
4. 이때 유효성 검사 실시. 다음 버전 번호는 현재 버전 번호보다 1만큼 큰 값이어야만 한다. 유효성 검사가 실패하면 트랜잭션은 중단되고 사용자는 2번부터 다시 모든 절차를 반복한다.

낙관적 락은 일반적으로 비관적 락보다 빠르다.
: 데이터베이스에 락을 걸지 않기 때문.
하지만 동시성 수준이 아주 높으면 성능이 급격하게 나빠진다.
-> 결국 1개의 클라이언트만 갱신에 성공하기 때문 (지속적인 재시도 발생)

장점

- 애플리케이션이 유효하지 않은 데이터를 편집하는 일을 막는다.
- 데이터베이스 자원에 락을 걸 필요가 없다. 버전 번호를 통해 애플리케이션에서 데이터 일관성을 유지한다.
- 낙관적 락은 데이터에 대한 경쟁이 치열하지 않은 상황에 적합. 락을 관리하는 비용 없이 트랜잭션 실행 가능

단점

- 데이터에 대한 경쟁이 치열한 상황에서는 성능이 좋지 못하다

##### 데이터베이스 제약 조건 (constraint)

테이블 자체에 제약 조건 추가

장점

- 구현이 쉽다
- 데이터에 대한 경쟁이 심하지 않을 때 잘 동작

단점

- 낙관적 락과 마찬가지로 데이터에 대한 경쟁이 심하면 실패하는 연산 수가 엄청나게 늘어날 수 있다.
- 데이터베이스 제약 조건은 애플리케이션 코드와 달라서 버전 통제가 어려움
- 제약 조건을 허용하지 않는 데이터베이스도 존재. 데이터베이스를 다른 제품으로 교체 시 문제가 발생할 수 있음

### 시스템 규모 확장

#### 데이터베이스 샤딩

데이터베이스의 규모를 늘리는 한 가지 방법 : 샤딩
-> 데이터베이스를 여러 대 두고, 각각에 데이터의 일부만 보관하도록 하는 것

데이터베이스 샤딩 시 데이터를 어떻게 분배할지 정해야 함.
호텔 예약 시스템의 대부분 질의를 hotel_id를 필터링 조건으로 사용하기 때문에 해당 키를 샤딩 조건으로 쓰면 좋다는 결론에 도달 가능.

#### 캐시

호텔 잔여 객실 데이터는 오직 현재 그리고 미래 데이터만 중요함.
-> 고객이 과거의 어떤 객실을 예약하지 않기 때문

낡은 데이터는 자동적으로 소멸되도록 TTL을 설정할 수 있다면 바람직
-> Redis.

데이터 로딩 속도와 데이터베이스 확장성이 문제가 되기 시작하면 데이터베이스 앞에 캐시 계층을 두고 잔여 객실 확인 및 객실 예약 로직을 해당 계층에서 실행하도록 할 수 있음
하지만, 잔여 객실에 대한 최종적 진실을 데이터베이스에 있기 때문에 데이터베이스 확인 필수

##### 캐시가 주는 새로운 과제

캐시 계층 추가 시 시스템의 확장성과 처리량은 대폭 증가, 데이터베이스와 캐시 사이의 데이터 일관성 유지에 관한 새로운 도전에 직면하게 됨

잔여 객실 데이터에 대한 변화를 데이터베이스에 먼저 반영하므로 캐시에는 최신 데이터가 없을 가능성이 존재.
-> 이런 불일치는 데이터베이스가 최종적으로 잔여 객실 확인을 하도록 하면 문제가 되지 않음

장점

- 읽기 질의를 캐시가 처리하므로 데이터베이스의 부하가 크게 줄어듬
- 읽기 질의를 메모리에서 실행하므로 높은 성능을 보장할 수 있음

단점

- 데이터베이스와 캐시 사이의 데이터 일관성을 유지하는 것을 어려운 문제. 데이터 불일치가 사용자 경험에 미칠 영향을 신중하게 따져보아야 함

#### 서비스 간 데이터 일관성

MSA 구조로 인한 각 서비스 간 독자적인 DB
-> 데이터 일관성 문제 야기

해결 방법

- 2PC(2-Phase Commit) : 여러 노드에 걸친 원자적 트랜잭션 실행을 보증하는 데이터베이스 프로토콜. 모든 노드가 성공하든 아니면 실패하든 둘 중 하나로 트랜잭션이 마무리되도록 보증. blocking 실행이므로 한 노드에 장애 발생 시 해당 장애가 복구될 때까지 진행이 중단됨.
- SAGA : 각 노드에 국지적으로 발생하는 트랜잭션을 하나로 엮은 것. 각각의 트랜잭션은 완료되면 다음 트랜잭션을 시작하는 트리거로 쓰일 메시지를 만들어 보낸다. 어느 한 트랜잭션이라도 실패하면 사가는 그 이전 트랜잭션의 결과를 전부 되돌리는 트랜잭션들을 순차적으로 실행.

# 11장. 결제 시스템

전자상거래를 가능하게 하는 것 : 결제 시스템

전자상거래 애플리케이션을 위한 결제 백엔드 구축
Q. 어떤 결제 방법을 지원?
A. 실생활에서 사용 가능한 모든 결제 옵션을 지원해야 함
Q. 신용 카드 결제 처리를 직접?
A. 전문 결제 서비스 업체 사용 (PSP)
Q. 신용 카드 데이터 저장 필요?
A. 결제 처리 업체에 의존
Q. 하루에 발생하는 결제 건수?
A. 하루 100만 건의 거래
Q. 매월 판매자에게 대금을 지급하는 절차 지원 필요?
A. 네

## 기능 요구사항

- 대금 수신 흐름 : 결제 시스템이 판매자를 대신하여 구매자의 대금을 수령
- 대금 정산 흐름 : 결제 시스템이 전 세계의 판매자에게 제품 판매 대금을 송금

## 비기능 요구사항

- 신뢰성 및 내결함성 : 결제 실패는 신중하게 처리되어야 함
- 내부 서비스와 외부 서비스간의 조정 프로세스 : 시스템 간의 결제 정보가 일치하는지 비동기적으로 확인

## 개략적 규모 측정

하루 100만 건의 결제 = 초당 10건의 TPS
-> RDB로도 처리 가능한 양
-> 처리 대역폭 대신 결제 트랜잭션의 정확한 처리에 초점

## 개략적 설계안

대금 수신 흐름
: 구매자가 주문을 하면 전자상거래 업체의 은행 계좌로 돈이 들어옴

대금 정산 흐름
: 제품 배송 완료 후 전자상거래 업체의 계좌에 묶여 있던 판매 대금에서 수수료를 제외한 잔액이 판매자의 은행 계좌로 지급

### 대금 수신 흐름

#### 결제 서비스

사용자로부터 결제 이벤트를 수락하고 결제 프로세스 조율
규정 준수 및 자금 세탁이나 테러 자금 조달과 같은 범죄 행위에 대한 위험 점검은 매우 복잡하고 고도로 전문화되어 있기 때문에 제3자 제공업체를 이용

#### 결제 실행자

결제 서비스 공급자(PSP)를 통해 결제 주문 실행
1개의 결제 이벤트는 여러 개의 결제 주문이 포함될 수 있다.

#### 결제 서비스 공급자

PSP. 실제로 계정에서 돈을 옮기는 역할을 담당

#### 원장

결제 트랜잭션에 대한 금융 기록
ex)
사용자가 판매자에게 1달러 결제
-> 사용자로부터 1달러 인출, 판매자에게 1달러 지급하는 기록

원장 시스템은 전자상거래 웹사이트의 총 수익을 계산하거나 향후 수익을 예측하는 등 결제 후 분석에서 매우 중요한 역할

#### 지갑

판매자의 계정 잔액을 기록
특정 사용자가 결제한 총 금액을 기록할 수도 있음

#### 일반적인 결제 흐름

1. 사용자가 주문하기 버튼을 클릭하여 결제 이벤트가 생성 -> 결제 서비스로 전송
2. 결제 서비스는 결제 이벤트를 데이터베이스에 저장
3. 결제 서비스는 결제 주문마다 결제 실행자 호출
4. 결제 실행자는 결제 주문을 데이터베이스에 저장
5. 결제 실행자가 외부 PSP 호출하여 결제 처리
6. 결제 실행자가 결제를 성공적으로 처리하고 나면 결제 서비스는 지갑을 갱신하여 특정 판매자의 잔고 기록
7. 지갑 서버는 갱신된 잔고 정보를 데이터베이스에 기록
8. 지갑 서비스가 판매자의 잔고를 성공적으로 갱신하면 결제 서비스는 원장을 호출
9. 원장 서비스는 새로운 원장 정보를 데이터베이스에 추가

### 결제 서비스 API

RESTful 설계 규칙 사용

주요 특징

- 전역적으로 고유한 ID를 멱등 키로 사용하여 중복 결제를 방지한다.
- 숫자는 전송 및 저장 시 문자열로 보관. 표시하거나 계산할 때만 숫자로 변환

### 결제 서비스 데이터 모델

결제 이벤트와 결제 주문, 2개의 테이블이 필요

결제 시스템용 저장소 솔루션을 고를 때 일반적으로 성능은 가장 중요한 고려사항이 아님

1. 검증된 안정성
2. 모니터링 및 데이터 탐사에 필요한 도구가 풍부하게 지원되는지
3. 데이터베이스 관리자 채용 시장이 성숙한지

일반적으로 NoSQL/NewSQL보다는 ACID 트랜잭션을 지원하는 전통적인 관계형 데이터베이스를 선호

결제 주문 테이블에는 결제 주문의 실행 상태를 유지하는 열거 자료형이 필요하다
ex) payment_order_status

실행 상태 종류

- NOT_STARTED, EXECUTING, SUCCESS, FAILED

업데이트 로직

1. payment_order_status의 초기 값 : NOT_STARTED
2. 결제 서비스가 결제 실행자에 주문 성공 후 payment_order_status : EXECUTING
3. 결제 서비스는 결제 처리자의 응답에 따라 payment_order_status : SUCCESS or FAILED

SUCCESS로 결정되면 결제 서비스는 지갑 서비스를 호출하여 판매자의 잔액을 업데이트하고 지갑이 업데이트되었다는 사실을 기록한다.
이 절차가 끝나면 결제 서비스는 원장 서비스를 호출하여 원장 데이터를 하고 원장 업데이트 사실을 기록한다.
동일한 checkout_id 아래의 모둔 결제 주문이 성공적으로 처리되면 결제 서비스는 결제 이벤트 테이블에 해당 결제가 완료되었다는 것을 업데이트한다.
-> 일반적으로 종결되지 않은 결제 주문을 모니터링하기 위해 주기적으로 실행되는 스케쥴 잡을 마련해둔다.
(임계값 형태로 설정된 기간이 지나도록 완료되지 않은 결제 주문이 있을 경우 알럿)

### 복식부기 원장 시스템

원장 시스템에는 복식부기라는 아주 중요한 설계 원칙 존재

복식부기는 모든 결제 시스템에 필수 요소이며 정확한 기록을 남기는 데 핵심적 역할을 한다.
모든 결제 거래를 두 개의 별도 원장 계좌에 같은 금액으로 기록한다.
모든 거래 항목의 합계는 0이어야 한다.
누군가 1센트를 잃으면 누군가는 1센트를 가져가야 한다.
이 시스템을 활용하면 자금의 흐름을 시작부터 끝까지 추적할 수 있으며 결제 주기 전반에 걸쳐 일관성을 보장할 수 있다.

### 외부 결제 페이지

대부분의 기업들은 신용 카드 정보를 내부에 저장하지 않음
: 신용 카드 정보를 내부에 저장할 시 복잡한 규정을 준수해야 하기 때문
-> PSP에서 제공하는 외부 신용 카드 페이지를 사용

- 웹사이트의 경우 위젯 또는 iframe
- 모바일 애플리케이션의 경우 결제 SDK에 포함된 사전에 구현된 페이지

### 대금 정산 흐름

타사 정산 서비스를 사용하여 전자상거래 웹사이트 은행 계좌에서 판매자 은행 계좌로 돈을 이체
대금 정산에서 다양한 부기 및 규제 요구사항이 존재하여 외부 업체를 이용함

## 상세 설계

### PSP 연동

대부분 회사는 두 가지 방법 중 하나로 결제 시스템을 PSP와 연동

1. 회사가 민감한 결제 정보를 안전하게 저장할 수 있다면 API를 통해 PSP와 연동하는 방법 선택 가능. 회사가 결제 웹페이지를 개발하고 민감한 결제 정보를 수집, PSP는 은행 연결, 다양한 카드 유형을 지원하는 역할
2. 복잡한 규정 및 보안 문제로 민감한 결제 정보를 저장하지 않기로 결정. PSP는 카드 결제 세부 정보를 수집하여 안전하게 저장할 수 있도록 외부 결제 페이즈를 제공. 대부분 기업이 택하는 접근법

#### 외부 결제 페이지 작동 방식

결제 서비스가 전체 결제 프로세스를 조율

1. 사용자가 결제 버튼 클릭 -> 클라이언트는 결제 주문 정보를 담아 결제 서비스 호출
2. 결제 주문 정보를 수신한 결제 서비스는 결제 등록 요청을 PSP로 전송. 결제 주문이 정확히 한 번만 등록될 수 있도록 UUID 필드 활용
3. PSP는 결제 서비스에 토큰을 반환. 토큰은 등록된 결제 요청을 유일하게 식별하는 PSP가 발급하는 UUID. 나중에 이 토큰을 사용하여 결제 등록 및 결제 실행 상태를 확인할 수 있음.
4. 결제 서비스는 PSP가 제공하는 외부 결제 페이지를 호출하기 전에 토큰을 데이터베이스에 저장
5. 토큰 저장 후 클라이언트는 PSP가 제공하는 외부 결제 페이즈를 표시
6. 사용자는 PSP의 웹 페이지에서 결제 세부 정보 입력 후 결제 진행 -> PSP가 결제 처리 시작
7. PSP가 결제 상태를 반환
8. 사용자는 리다이렉션 URL이 가리키는 웹 페이지로 보내짐
9. 비동기적으로 PSP는 웹훅을 통해 결제 상태와 함께 결제 서비스를 호출. 웹훅은 결제 시스템 측에서 PSP를 처음 설정할 때 등록한 URL. 결제 시스템이 웹훅을 통해 결제 이벤트를 다시 수신하면 결제 상태를 추출하여 결제 주문 데이터베이스 테이블의 payment_order_status를 최신 상태로 업데이트

위 9개의 단계는 각각 네트워크 문제로 실패할 수 있다.
실제로 장애가 발생하면 체계적으로 처리할 수 있는 방법 : 조정

### 조정

시스템 구성 요소가 비동기적으로 통신하는 경우 메시지가 전달되거나 응답이 반환된다는 보장이 없음
정확성 보장 방법? : 조정
-> 관련 서비스 간의 상태를 주기적으로 비교하여 일치하는지 확인하는 것
: 일반적으로 결제 시스템의 마지막 방어선
: 결제 시스템의 내부 일관성을 확인할 때도 사용

조정 중에 발견된 차이는 일반적으로 재무팀에 의뢰하여 수동으로 고친다.
발생 가능한 불일치 문제 및 해결 방안은 3가지 범주로 나눌 수 있다.

1. 어떤 유형의 문제인지 알고 있으며 문제 해결 절차를 자동화할 수 있는 경우 : 원인과 해결 방법을 알고 있으며, 자동화 프로그램을 만드는 것이 비용 효율적인 경우
2. 어떤 유형의 문제인지는 알지만 문제 해결 절차를 자동화할 수는 없는 경우 : 불일치의 원인과 해결 방법을 알고는 있지만 자동 조정 프로그램의 작성 비용이 너무 높다. 발생한 불일치 문제는 작업 대기열에 넣고 재무팀에서 수동으로 수정하도록 한다.
3. 분류할 수 없는 유형의 문제인 경우 : 불일치가 어떻게 발생하였는지 알지 못하는 경우. 특별 작업 대기열에 넣고 재무팀에서 조사하도록 한다.

### 결제 지연 처리

결제 요청이 평소보다 오래 걸리게 되는 몇 가지 경우가 존재한다.

1. PSP가 해당 결제 요청의 위험성이 높다고 보고 담당자 검토를 요구하는 경우
2. 신용 카드사가 구매 확인 용도로 카드 소유자의 추가 정보를 요청, 추가 보호 장치를 요구하는 경우

결제 서비스는 이렇게 처리하는데 시간이 오래 걸리는 요청도 처리할 수 있어야 한다.
구매 페이지가 외부 PSP에 호스팅되는 PSP는 다음과 같이 처리한다.

- PSP는 결제가 대기 상태임을 알리는 상태 정보를 클라이언트에 반환하고, 클라이언트는 이를 사용자에게 표시한다.
- PSP는 우리 회사를 대신하여 대기 중인 결제의 진행 상황을 추적하고, 상태가 바뀌면 PSP에 등록된 웹훅을 통해 결제 서비스에 알린다.

결제 요청이 최종적으로 완료되면 PSP는 사전에 등록된 웹훅을 호출 -> 결제 서비스는 내부 시스템에 기록된 정보를 업데이트하고 고객에게 배송을 완료한다.

### 내부 서비스 간 커뮤니케이션

#### 동기식 통신

HTTP와 같은 동기식 통신은 소규모 시스템에서 잘 작동하지만 규모가 커지면 단점이 분명해짐

- 성능 저하 : 요청 처리에 관계된 서비스 가운데 하나에 발생한 성능 문제가 전체 시스템의 성능에 영향을 끼친다.
- 장애 격리 곤란 : PSP 등의 서비스에 장애가 발생하면 클라이언트는 더 이상 응답을 받지 못한다.
- 높은 결합도 : 요청 발신자는 수신자를 알아야만 한다.
- 낮은 확장성 : 큐를 버퍼로 사용하지 않고서는 갑작스러운 트래픽 증가에 대응할 수 있도록 시스템을 확장하기 어렵다.

#### 비동기 통신

- 단일 수신자 : 각 요청은 하나의 수신자 또는 서비스가 처리. 공유 메시지 큐를 사용하여 구현하고 처리된 메시지는 큐에서 바로 삭제됨
- 다중 수신자 : 각 요청은 여러 수신자 또는 서버가 처리. 카프카는 이런 시나리오를 잘 처리.

동기식 통신은 설계하기는 쉽지만 서비스의 자율성을 높이기에는 적합하지 않다.
의존성 그래프가 커지면 전반적 성능은 낮아지낟.
비동기 통신은 설계의 단순성과 데이터 일관성을 시스템 확장성 및 장애 감내 능력과 맞바꾼 결과

### 결제 실패 처리

모든 결제 시스템은 실패한 결제를 적절히 처리할 수 있어야 한다.
안정성 및 결함 내성은 결제 시스템의 핵심적 요구사항

#### 결제 상태 추적

결제 주기의 모든 단계에서 결제 상태를 정확하게 유지하는 것은 매우 중요.
실패가 일어날 때마다 결제 거래의 현재 상태를 파악하고 재시도 또는 환불이 필요한지 여부를 결정.

#### 재시도 큐 및 실패 메시지 큐

- 재시도 큐 : 일시적 오류 같은 재시도 가능 오류는 재시도 큐에 보낸다.
- 실패 메시지 큐 : 반복적으로 처리에 실패한 메시지는 결국에는 실패 메시지 큐로 보낸다. 이 큐는 문제가 있는 메시지를 디버깅하고 격리하여 성공적으로 처리되지 않은 이유를 파악하기 위한 검사에 유용하다.

### 정확히 한 번 전달

결제 시스템에 발생할 수 있는 가장 심각한 문제 중 하나는 고객에게 이중으로 청구하는 것
-> 결제 주문이 정확히 한 번만 실행되도록 설계해야 함

메시지를 정확히 한 번 전달하는 것은 매우 어려운 문제이기도 하지만 문제를 두 부분으로 나누면 훨씬 쉽게 해결 가능

1. 최소 한 번은 실행된다. -> 재시도
2. 최대 한번만 실행된다. -> 멱등성 검사

#### 재시도

네트워크 오류나 시간 초과로 인해 결제 거래를 다시 시도해야 하는 경우가 존재
-> 재시도 메커니즘을 활용하여 어떤 결제가 최소 한 번은 실행되도록 보장 가능

재시도 메커니즘 도입 시 얼마나 간격을 두고 재시도할지 정하는 것이 중요

- 즉시 재시도 : 클라이언트는 즉시 요청을 다시 보낸다.
- 고정 간격 : 재시도 전에 일정 시간 기다리는 방안.
- 증분 간격 : 재시도 전에 기다리는 시간을 특정한 양 만큼 점진적으로 늘려 나가는 방안.
- 지수적 백오프 : 재시도 전에 기다리는 시간을 직전 재시도 대비 두 배씩 늘려 나가는 방안.
- 취소 : 요청을 철회하는 방안. 실패가 영구적이거나 재시도를 하더라도 성공 가능성이 낮은 경우에 흔히 사용되는 방안.

적절한 재시도 전략을 결정하는 것은 어렵다.
일반적으로 적용 가능한 지침은 네트워크 문제가 단시간 내에게 해결될 것 같지 않다면 지수적 백오프를 사용하는 것이 좋음.
에러 코드를 반환할 때는 Retry-After 헤더를 같이 붙여 보내는 것이 바람직하다.

재시도 시 발생할 수 있는 잠재적 문제 : 이중 결제
두 가지 시나리오

- 클라이언트가 결제 버튼을 두 번 중복 클릭한다.
- PSP가 결제를 성공적으로 처리하였으나 네트워크 오류로 인해 응답이 결제 시스템에 도달하지 못했다. 사용자가 다시 결제 버튼을 클릭하거나 클라이언트가 다시 결제를 시도한다.

이중 결제 방지를 위해서는 결제가 최대 한 번 이루어져야 한다.
-> 멱등성

#### 멱등성

최대 한 번 실행을 보장하기 위한 핵심 개념
수학 또는 컴퓨터 과학적 연산이 가질 수 있는 한 가지 속성으로, 연산을 여러 번 실행하여도 최초 실행 결과가 그대로 보존되는 특정을 일컫는다.
API 관점에서 보자면 멱등성은 클라이언트가 같은 API 호출을 여러 번 반복해도 항상 동일한 결과가 나온다는 것
결제 요청의 멱등성을 보장하기 위해서 HTTP 헤더에 멱등 키 : 값 형태로 멱등 키를 추가하면 된다.

시나리오 1 : 고객이 결제 버튼을 빠르게 두 번 클릭하는 경우
사용자의 두 번 결제 요청으로 동일한 멱등 키를 포함한 HTTP 요청이 결제 시스템에 전송된다.
결제 시스템은 두 번째 요청에 포함된 멱등 키를 이전에 받은 적이 있기 때문에 해당 요청은 재시도로 간주한다. -> 이전 결제 요청의 가장 최근 상태를 반환한다.

동일한 멱등 키로 동시에 많은 요청을 받으면 결제 서비스는 그 중 하나의 요청만 처리하고 나머지 429 Too Many Requests 상태 코드를 반환한다.

멱등성을 지원하는 한 가지 방법 : 데이터베이스 Unique 제약조건 활용

시나리오 2 : PSP가 결제를 성공적으로 처리, but 네트워크 오류로 응답이 결제 시스템에 전달되지 못하여 사용자가 다시 결제 버튼을 클릭하는 경우
결제 서비스는 PSP에 비중복 난수를 전송하고 PSP는 해당 난수에 대한 토큰을 반환한다.
이 난수는 결제 주문을 유일하게 식별하는 구실 & 그 난수에 일대일로 대응됨
-> 토큰 또한 결제 주문을 유일하게 식별 가능

사용자가 결제 버튼을 다시 누른다 해도 결제 주문이 같으니 PSP로 전달되는 토큰도 같다.
PSP는 이 토큰을 멱등 키로 사용하므로 이중 결제로 판단하고 종전 실행 결과를 반환

### 일관성

결제 실행 과정에서 상태 정보를 유지 관리하는 여러 서비스가 호출된다.

1. 결제 서비스 : 비중복 난수, 토큰, 결제 주문, 실행 상태 등의 결제 고나련 데이터를 유지 관리
2. 원장 : 모든 회계 데이터를 보관
3. 지갑 : 판매자의 계정 잔액을 유지
4. PSP : 결제 실행 상태를 유지
5. 데이터의 안정성을 높이기 위해 여러 데이터베이스 사본에 복제

분산 환경에서는 서비스 간 통신 실패로 데이터 불일치가 발생할 수 있음
결제 시스템에서 발생 가능한 데이터 일관성 문제를 해결하는 기법들

내부 서비스 간에 데이터 일관성을 유지하려면 요청이 정확히 한 번 처리되도록 보장하는 것이 아주 중요
내부 서비스와 외부 서비스 간의 데이터 일관성 유지를 위해서는 멱등성과 조정 프로세스를 사용.
외부 서비스가 멱등성을 지원하는 경우, 결제를 재시도할 대는 같은 멱등 키를 사용해야 함.
하지만 외부 서비스를 항상 옳다고 가정할 수 없으므로 조정 절차도 필수.

데이터 다중화 시에는 복제 지연으로 인해 기본 데이터베이스와 사본 데이터가 불일치하는 일이 생길 수 있음
2가지 해결 방법

1. 주 데이터베이스에서만 읽기와 쓰기 연산을 처리. 이 접근법은 설정하기는 쉽지만 규모 확장성이 떨어짐.
2. 모든 사본이 항상 동기화되도록한다. 합의 기반 분산 데이터 사용 가능

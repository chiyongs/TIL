# 06. 파티셔닝

대체로 각 데이터 단위를 1개의 파티션으로 만든다.
그 자체로 1개의 작은 데이터베이스.
파티셔닝을 하는 주 된 원인은 확장성

단일 파티션에 실행되는 질의를 각 노드에서 자신의 파티션으로 해당 질의를 독립적으로 실행하게 되면
-> 노드를 추가할 때마다 질의 처리량이 증가

## 파티셔닝과 복제

1개의 노드에 여러 파티션이 존재 가능
각 노드에서 각 파티션은 리더일 수도 있고 팔로워일 수도 있다.
: 리더-팔로워 복제 모델

## 키-값 데이터 파티셔닝

파티셔닝 : 데이터와 질의 부하를 각 노드에 균등하게 분산시키는 것
동일한 분량을 담당한다는 가정 하에 1개의 노드가 10개의 노드가 되면
-> 10배의 데이터를 저장할 수 있고, 10배의 읽기, 쓰기 요청에 대한 처리가 가능

쏠림 : 파티셔닝이 고르게 이루어지지 않아 다른 파티션보다 데이터가 많거나 질의 처리를 많이 하는 파티션이 존재하는 경우
핫스팟 : 불균형하게 부하가 높은 파티션

핫스팟을 해결하는 가장 쉬운 방법
: 데이터 저장 시 무작위로 분산하여 저장
-> 데이터를 모두 고르게 분산할 수 있지만, 데이터 탐색 시 모든 노드에서 병렬적으로 탐색을 수행해야 함

키-값 데이터 모델
: 항상 기본 키를 통해 레코드에 접근
-> 항상 빨리 찾을 수 있다.
ex) 백과사전

## 키 범위 기준 파티셔닝

파티셔닝 방법 : 백과사전
각 파티션에 연속된 범위의 키를 할당
-> 각 범위의 경계를 알면 데이터를 어디에 저장했는지 파악이 쉬움
(어느 키가 어느 파티션에 속하는지)

각 파티션이 어느 노드에 할당되어 있는지 알면 적절한 노드로 요청도 가능

키 범위가 파티션별로 동일할 필요는 없다.
데이터에 맞게 범위는 조정되어야 한다.
그렇지 않으면 데이터 쏠림 현상이 발생할 수 있다.

각 파티션 내에서 키는 정렬된 순서로 유지된다.
그로 인해 빠르게 탐색이 가능하다.
하지만, 키 범위 기준 파티셔닝은 특정 접근 패턴에 대해 핫스팟을 유발할 수 있다.
예를 들어, 타임스팸프가 키라면 해당 날짜에 대한 파티션만 부하를 받고 나머지는 유휴 상태로 유지

## 키의 해시값 기준 파티셔닝

쏠림과 핫스팟 위험때문에 많은 분산 데이터 스토어는 키의 파티션을 정하는데 해시함수를 적용
좋은 해시 함수 : 쏠린 데이터를 균일하게 분산
암호적으로 강력할 필요는 없다.
ex) 카산드라와 몽고DB : MD5, 볼드모트 : 파울러-놀-보
프로그래밍 언어에서 지원하는 내장 해시 함수는 파티셔닝에는 적합 X

각 파티션에 해시값 범위 할당하고, 해시값이 파티션 범위에 속하는 모든 키를 해당 파티션에 할당
-> 키를 파티션에 균일하게 분산시키기에 좋음
하지만, 키의 해시값으로 파티셔닝하면 범위 질의를 효율적으로 실행할 수 있는 키 범위 파티셔닝의 장점을 잃어버림
-> 인접했던 키들이 모든 파티션에 흩어져서 정렬 순서가 유지되지 않기 때문
-> 해시값으로 파티셔닝하면 범위 질의가 모든 파티션에 전송되어야 함

카산드라는 두 가지 파티셔닝(키 범위 기준 파티셔닝, 키의 해시값 기준 파티셔닝)에서 타협

- 여러 칼럼을 포함하는 복합 기본키 지정

첫 번째 키에만 해싱을 적용해 파티션 결정에 사용
남은 키에는 데이터를 정렬하는 연쇄된 색인으로 사용
-> 복합 키의 첫 번째 칼럼에 대해서 값 범위로 검색하는 질의는 사용 불가
-> 하지만, 첫 번째 칼럼에 고정된 값 적용하면 다른 칼럼에 대해서는 효율적인 범위 스캔 가능

이로인해 연쇄된 색인을 사용하면 일대다 관계를 표현하는 우아한 데이터 모델 설계 가능

## 쏠린 작업부하와 핫스팟 완화

키의 해시값으로 파티셔닝 -> 핫스팟을 줄이는데 도움
하지만, 핫스팟을 완벽히 제거는 불가능
항상 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.
ex) SNS에서 수 백만명의 팔로워를 거느린 유명인의 행동
(동일한 ID의 해시값은 동일 -> 해싱은 도움 X)

현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정 불가능
-> 애플리케이션에서 쏠림을 완화해야 함.
요청이 매우 많이 쏠리는 키를 발견했을 때의 간단한 해결책
: 각 키의 시작이나 끝에 임의의 숫자를 붙이는 것
이로써 한 키에 대한 쓰기 작업이 여러 개의 다른 키로 균등하게 분산, 그 키들은 다른 파티션으로 분산
하지만, 다른 키에 쪼개서 쓰면 발생하는 단점
: 추가적인 작업 필요

- 여러 개의 키에 해당하는 데이터를 읽어서 조합해야 함 & 추가적으로 저장해야 할 정보도 존재
  -> 요청이 몰리는 소수의 키에만 적용하는 게 타당
  쓰기 처리량이 낮은 대다수의 키에도 적용 시 불필요한 오버헤드 발생

## 파티셔닝과 보조 색인

키-값 데이터 모델로 파티셔닝을 진행
레코드를 기본 키를 통해 접근하여 읽기/쓰기 요청을 전달

보조 색인이 연관되면 복잡해진다.

보조 색인 (ex. like %hogual%, color = 'RED')

- 레코드를 유일하게 식별하는 용도 X
- 특정 값이 발생한 항목을 검색하는 수단
- 관계형 데이터베이스의 핵심 요소
- 엘라스틱 서치와 같은 검색 서버에게는 존재의 이유
- 파티셔닝에 깔끔하게 대응되지 않음

보조 색인이 존재하는 데이터베이스를 파티셔닝하는 방법

- 문서 기준 보조 색인 파티셔닝
- 용어 기준 보조 색인 파티셔닝

### 문서 기준 보조 색인 파티셔닝

- 각 파티션 별로 독립적으로 운영
- 각 파티션 별로 자신의 보조 색인을 유지하며 해당 파티션에 속하는 문서만 담당
- 쓰기 작업 시 해당하는 파티션에만 작업이 발생하므로 쓰기 작업에 대한 비용이 낮음
  -> 지역 색인

하지만, 문서 기준 보조 색인 파티셔닝 시에는 읽기에 대한 부담이 존재.
특정 값에 해당하는 데이터가 동일한 파티션에 저장되리라는 보장이 없음
-> 특정 값을 찾기 위해 모든 파티션에 질의를 요청하여 얻은 결과를 모아야 함
-> 스캐더/개더 (scatter / gather)
보조 색인을 사용해서 읽는 질의는 큰 비용이 들게 됨

여러 파티션에서 질의를 병렬 실행하더라도 스캐더/개더는 꼬리 시간 지연 증폭이 발생하기 쉬움
하지만, 많은 데이터베이스에서 보조 색인을 문서 기준으로 파티셔닝하는 경우가 많다.

### 용어 기준 보조 색인 파티셔닝

용어 : 문서에 존재하는 모든 단어
용어 기준 보조 색인 파티셔닝
: 찾고자 하는 용어에 따라 색인의 파티션이 결정되는 파티셔닝 방법
모든 파티션의 데이터를 담당하는 전역 색인을 만듦
한 노드에만 색인을 저장하지 않음 (해당 노드가 병목이 되어 파티셔닝의 목적을 해침)
전역 색인 자체를 파티셔닝할 수 있음

파티셔닝 방법

- 용어 자체
  - 범위 스캔에 적합
- 용어의 해시 값
  - 부하 분산에 적합

용어를 포함하는 파티션으로만 요청을 보내면 되기 때문에 읽기가 효율적임
하지만, 쓰기가 느리고 복잡함
단일 문서를 쓸 때 해당 색인의 여러 파티션에 영향을 줄 수 있기 때문 (문서에 있는 모든 용어가 다른 노드에 있는 다른 파티션에 속할 수 있음)
따라서, 대개 비동기로 갱신 (이론적으로는 분산 트랜잭션으로 실행해야 하지만, 모든 데이터베이스에서 지원하지 않음)

## 파티션 재균형화

- 질의 처리량 증가 -> 늘어난 부하 처리 필요 -> CPU 추가
- 데이터셋 크기 증가 -> 데이터 저장에 사용될 디스크와 램 추가
- 장비에 장애 발생 -> 역할을 다른 장비가 넘겨받아야 함
  이런 변화가 발생하면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다.

-> 재균형화
: 클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정

재균형화의 최소 요구사항

- 재균형화 후 부하는 클러스터 내의 모든 노드들 사이에 균등하게 분배되어야 함
- 재균형화 도중에도 읽기 쓰기 요청을 받아들여야 함
- 재균형화가 빨리 실행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에서 필요 이상으로 데이터 이동이 발생해서는 안됨

### 재균형화 전략

#### 쓰면 안 되는 방법 : 해시 값에 모드 N 연산을 실행

키의 해시값 기준으로 파티셔닝 시 사용 가능한 해시값 범위를 나누고 각 범위를 한 파티션에 할당하는 게 최선
-> 왜 모드 연산을 사용하지 않을까?
예를 들어, 노드 10대가 있고 각각 0부터 0까지 숫자를 배정하면 각 키를 노드에 할당하는 것은 매우 쉬움

모드 N 방식의 문제
: 노드 개수 N이 바뀌면 대부분의 키가 노드 사이에 옮겨져야 한다는 점
노드가 10대일 때랑, 11대, 12대일 때 키가 계속 노드 사이에서 옮겨져야 한다.
-> 키가 자주 이동하면 재균형화 비용이 지나치게 커진다.

#### 파티션 개수 고정

파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당
예) 노드 10대로 구성된 클러스터에서 실행되는 데이터베이스, 1000개의 파티션으로 쪼개고 각 노드마다 약 100개의 파티션 할당

클러스터에 노드 추가
-> 새 노드는 파티션이 다시 균일하게 분배될 때까지 기존 노드에서 파티션 몇 개를 뺏어옴
클러스터에서 노드 제거
-> 기존 노드의 파티션을 다른 노드로 분배

파티션은 노드 사이에서 통째로 이동하기만 한다.
파티션 개수는 변경 X, 파티션에 할당된 키도 변경 X
유일한 변화 : 노드에 어떤 파티션이 할당되는가

파티션 할당 변경은 즉시 반영되지 않고 네트워크를 통해 대량의 데이터를 전송해야 함
-> 시간이 좀 걸리는 작업
-> 데이터 전송이 진행 중인 동안에 읽기나 쓰기가 실행되면 기존에 할당된 파티션을 사용한다.

리악, 엘라스틱서치, 카우치베이스, 볼드모트에서 파티션 개수 고정 재균형화 방법 사용

보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변화하지 않는다.
-> 파티션 개수 고정 -> 운영 단순
-> 처음 설정된 파티션 개수가 사용 가능한 노드 대수의 최대치
-> 미래에 증가될 것을 수용하기에 충분히 높은 값으로 선택

#### 동적 파티셔닝

키 범위 파티셔닝을 사용하는 데이터베이스에서 파티션 경계와 개수가 고정되어 있는 것은 매우 불편
파티션 경계를 잘못 지정하면 모든 데이터가 한 파티션에 저장되고 나머지 파티션은 더 빌 수도 있다.
(예. 날짜로 파티셔닝 시 해당 날짜가 아니면 비어있음)
-> 키 범위 파티셔닝 사용 데이터베이스는 동적으로 파티션을 만든다.

파티션 크기가 설정된 값을 넘어서면 파티션을 두 개로 쪼개 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다.
데이터가 많이 삭제되어 파티션 크기가 임곗값 아래로 떨어지면 인접한 파티션과 합쳐질 수 있다.
(B 트리의 최상위 레벨에서 실행되는 작업과 유사)

파티션 개수가 고정된 경우와 마찬가지로 각 파티션은 노드 하나에 할당되고 각 노드는 여러 파티션을 담당할 수 있다.

동적 파티셔닝의 이점
: 파티션 개수가 전체 데이터 용량에 맞춰 조정된다

데이터 양이 작으면 파티션 개수도 적어도 되므로 오버헤드도 적다.
데이터 양이 거대하면 개별 파티션의 크기는 설정된 최대치로 제한된다.

하지만, 빈 데이터베이스의 경우 파티션 경계를 어디로 정해야 하는지에 관한 사전 정보가 없음
-> 파티션이 1개
-> 데이터 셋이 작을 때는 모든 쓰기 요청이 하나의 노드에서 실행되고 다른 노드들은 유휴 상태
-> 이 문제를 완화하기 위해 빈 데이터베이스에 초기 파티션 집합을 설정할 수 있음
: 사전 분할
(키 범위 파티셔닝의 경우 사전 분할을 하려면 키가 어떤 식으로 분할될지 미리 알아야 함)

동적 파티셔닝은 키 범위 파티셔닝에만 적합한 것은 아니고 해시 파티셔닝에도 똑같이 사용될 수 있음

#### 노드 비례 파티셔닝

파티션 개수가 노드 대수에 비례하도록 파티셔닝
-> 노드당 할당되는 파티션 개수를 고정
-> 노드 대수가 변함 없는 동안은 개벌 파티션의 크기가 데이터셋 크기에 비례해서 증가
-> 노드 대수를 늘리면 파티션의 크기는 작아진다.
데이터 용량이 클수록 데이터를 저장할 노드도 많이 필요
-> 개별 파티션 크기도 상당히 안정적으로 유지
(카산드라와 케티마에서 사용)

새 노드가 클러스터에 추가되면
-> 고정된 개수의 파티션을 무작위로 선택해 분할
-> 각 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당
파티션을 무작위로 분할해 균등하지 않은 분할이 생길 수 있지만, 여러 파티션에 대해 평균적으로 보면 새 노드는 기존 노드들이 담당하던 부하에서 균등한 몫을 할당받게 된다.

파티션 경계를 무작위로 선택하려면 해시 기반 파티셔닝을 사용해야 한다.
(해시 함수를 통해 생성된 숫자 범위로부터 파티션 경게를 선택할 수 있도록)

## 요청 라우팅

클라이언트에서 요청을 어디로 보내야하지?
-> 요청을 처리할 수 있는 노드는 어디에 있지?
-> 서비스 찾기 : Service Discovery
고가용성을 지향하는 소프트웨어에서 고민해야하는 문제

Service Discovery 방법

1. 클라이언트에서 아무 노드에게 요청

- 해당 노드가 처리 가능하면 처리하고, 불가능하면 처리 가능한 노드에게 요청 전달

2. 클라이언트가 라우팅 계층으로 요청

- 라우팅 계층이 요청을 처리할 수 있는 노드로 요청을 전달

3. 클라이언트가 요청을 처리할 수 있는 노드를 알고 있어 직접 해당 노드로 요청

많은 분산 데이터 시스템은 클러스터 메타데이터를 추적하기 위해 주키퍼와 같은 별도의 코디네이션 서비스 사용
각 노드는 주키퍼에 자신을 등록 & 주키퍼는 파티션과 노드 사이의 신뢰성 있는 할당 정보를 관리
라우팅 계층이나 파티션 인지 클라이언트 같은 다른 구성 요소들은 주키퍼에 있는 정보를 구독
파티션의 소유주 변경, 노드 추가, 삭제에 대해 주키퍼는 라우팅 계층에 이를 알려서 라우팅 정보를 최신으로 유지하도록 함

카프카 : 주키퍼 사용
몽고DB : 자체 설정 서버 사용, 몽고스 데몬을 라우팅 계층으로 사용
카산드라 : 가십 프로토콜 사용 -> 클러스터 상태 변화를 노드에 퍼뜨림
-> 1번 방식과 같이 아무 노드나 요청을 받을 수 있고 올바른 노드에게 요청 전달
-> 데이터베이스 노드에 복잡성 증가 but, 외부 코디네이션 서비스 의존 X

## 병렬 질의 실행

MPP : Massively Parallel Processing
대규모 병렬 처리 -> 분석용으로 자주 사용

복잡한 질의를 여러 실행단계와 파티션으로 분해
-> 서로 다른 노드에서 병렬적으로 처리

## 정리

저장하고 처리할 데이터가 너무 많아서 장비 한 대로 처리하는게 불가능
-> 파티셔닝 필요

파티셔닝의 목적
: 핫스팟이 생기지 않게 하면서 데이터와 질의 부하를 여러 장비에 균일하게 분배

파티셔닝 기법

1. 키 범위 파티셔닝
   : 키가 정렬되어있고 개별 파티션은 어떤 최솟값과 최댓값 사이에 속하는 모든 키를 담당

- 범위 질의 효율적 (키 순서 보장 O)
- 정렬 순서가 서로 가까운 키에 자주 접근 시 핫스팟 생김

2. 해시 파티셔닝
   : 각 키에 해시 함수를 적용, 각 파티션은 특정 범위의 해시값을 담당

- 범위 질의 비효율적 (키 순서 보장 X)
- 부하를 더욱 고르게 분산 가능
- 해시 파티셔닝 사용 시 보통 고정된 개수의 파티션을 미리 만들어 각 노드에 몇 개씩 파티션을 할당하며 노드가 추가되거나 제거되면 파티션을 통째로 노드 사이에서 이동

두 가지 파티셔닝 전략을 섞어서 사용 가능
: 키의 일부분은 파티션 식별용, 나머지 부분은 정렬 순서용으로 만든 복합키 사용
예) 카산드라

보조 색인 파티셔닝 기법

- 문서 기반 보조 색인 파티셔닝 (지역 색인)
  : 보조 색인을 기본 키와 값이 저장된 파티션에 저장
  -> 쓸 때는 하나의 파티션만 갱신
  -> 읽을 때 모든 파티션에 걸쳐 스캐더/개더 실행
- 용어 기반 보조 색인 파티셔닝 (전역 색인)
  : 색인된 값을 사용하여 보조 색인을 별도로 파티셔닝
  -> 보조 색인 항목은 기본키의 모든 파티션에 있는 레코드를 포함할 수도 있음
  -> 쓸 때는 보조 색인 여러 개를 갱신
  -> 읽기는 단일 파티션에서 실행

# 07. 트랜잭션

시스템의 신뢰성 : 결함을 처리하여 전체 시스템의 치명적인 장애로 이어지는 것을 막아야 함
트랜잭션은 시스템의 신뢰성에 대한 문제를 단순화하는 메커니즘으로 채택되어 왔다.

트랜잭션 : 애플리케이션에서 몇 개의 읽기와 쓰기를 하나의 논리적 단위로 묶는 방법
-> 1개의 트랜잭션 내 모든 읽기와 쓰기는 1개의 연산으로 실행
-> 전체가 성공하거나 실패한다.

따라서, 트랜잭션이 실패한다면 애플리케이션에서 안전하게 재시도 가능
(부분적인 실패를 걱정하지 않아도 되기 때문)

## 애매모호한 트랜잭션의 개념

현대의 거의 모든 관계형 데이터베이스와 일부 비관계형 데이터베이스는 트랜잭션을 지원한다.
2000년대 후반 비관계형 데이터베이스가 인기를 끌기 시작하면서 대다수는 트랜잭션을 지원하지 않았다.
-> 트랜잭션은 확장성의 안티체제이며 높은 성능과 고가용성 유지를 위해서는 트랜잭션을 포기해야한다는 믿음이 생김

하지만, 아니다

### ACID의 의미

트랜잭션이 제공하는 안전성 보장 : ACID

- Atomicity : 원자성
- Consistency : 일관성
- Isolation : 격리성
- Durability : 지속성

ACID 표준을 따르지 않는 시스템을 때로 BASE로 부름

- Basically Available : 기본적으로 가용성 제공
- Soft State : 유연한 상태
- Eventually Consistency : 최종적 일관성

#### 원자성, Atomicity

원자적 : 더 작은 부분으로 쪼갤 수 없는 무언가
예) 다중 스레드 프로그래밍에서 한 스레드가 원자적 연산을 실행 -> 다른 스레드에서 절반만 완료된 연산을 관찰할 수 없음
시스템은 연산을 실행하기 전이나 실행한 후의 상태만 존재하고 그 중간 상태에는 머물 수 없다.

ACID의 맥락에서 원자성은 동시성과 관련이 없다.
원자성은 여러 프로세스가 동시에 같은 데이터에 접근하려고 할 때 무슨 일이 생기는지 설명하지 않는다.
-> 이 문제는 격리성과 관련이 있다.

원자성은 클라이언트가 쓰기 작업 몇 개를 실행하려고 하는데 그 중 일부만 처리된 후 결함이 발생하면 무슨 일이 생기는지 설명한다.
여러 쓰기 작업이 하나의 원자적인 트랜잭션으로 묶여 있는데 결함 때문에 완료될 수 없다면 어보트 되고 데이터베이스는 이 트랜잭션에서 지금까지 실행한 쓰기를 무시하거나 취소해야 한다.

원자성이 없으면 애플리케이션에서 동일한 변경이 2번 실행되어서 중복되거나 잘못된 데이터가 만들어지기 쉽다.
-> 원자성은 이 문제를 단순하게 만들어준다.

오류가 생겼을 때 : 트랜잭션을 어보트, 해당 트랜잭션에서 기록한 모든 내용을 취소하는 능력
-> 원자성의 결정적인 특징

#### 일관성, Consistency

ACID의 맥락에서 일관성 : 데이터베이스가 좋은 상태에 있어야 한다는 것의 애플리케이션에 특화된 개념
일관성의 아이디어 : 항상 진실이어야 하는 데이터에 관한 어떤 선언이 있다는 것
예) 회계 시스템에서 모든 계좌에 걸친 대변과 차변은 항상 맞아떨어져야 한다.
트랜잭션이 이런 불변식이 유효한 데이터베이스에서 시작하고 트랜잭션에서 실행된 모든 쓰기가 유효성을 보존한다면 불변식이 항상 만족된다고 확신 가능

일관성의 아이디어는 애플리케이션의 불변식 개념에 의존하고, 일관성을 유지하도록 트랜잭션을 올바르게 정의하는 것은 애플리케이션의 책임이다.
-> 데이터베이스가 보장할 수 있는 것이 아님

원자성, 격리성, 지속성은 데이터베이스의 속성 but, 일관성은 애플리케이션의 속성
애플리케이션에서 일관성을 달성하기 위해 데이터베이스의 원자성과 격리성 속성에 기댈 수는 있지만 데이터베이스만으로 되는 것은 아니다.

#### 격리성, Isolation

대부분 동시에 여러 클라이언트에서 데이터베이스에 접속한다.
-> 동일한 데이터베이스 레코드에 접근하면 동시성 문제(경쟁 조건, Race Condition)에 맞닥뜨리게 된다.

ACID에서 격리성 : 동시에 실행되는 트랜잭션은 서로 격리된다는 것을 의미
트랜잭션은 다른 트랜잭션을 방해할 수 없다.
고전적인 데이터베이스 교과서에서는 격리성을 직렬성이라는 용어로 공식화한다.
직렬성 : 각 트랜잭션이 전체 데이터베이스에서 실행되는 유일한 트랜잭션인 것처럼 동작할 수 있다는 것을 의미
-> 데이터베이스는 실제로는 여러 트랜잭션이 동시에 실행됐더라도 트랜잭션이 커밋되었을 때의 결과가 트랜잭션이 순차적으로 실행됐을 때의 결과와 동일하도록 보장한다.

하지만, 직렬성 격리(Serializable Isolation)은 성능 손해를 동반 -> 현실에서는 거의 사용하지 않음

#### 지속성, Durability

지속성 : 트랜잭션이 성공적으로 커밋됐다면 하드웨어 결함이 발생하거나 데이터베이스가 죽더라도 트랜잭션에서 기록한 모든 데이터는 손실되지 않는다는 보장
지속성을 보장하려면 데이터베이스는 트랜잭션이 성공적으로 커밋됐다고 보고하기 전에 쓰기나 복제가 완료될 때까지 기다려야 한다.

### 단일 객체 연산과 다중 객체 연산

다중 트랜잭션 : 어떤 읽기 연산과 쓰기 연산이 동일한 트랜잭션에 속하는지 알아낸 수단이 있어야 한다.
관계형 데이터베이스에서는 클라이언트와 데이터베이스 서버 사이의 TCP 연결을 기반으로
어떤 특정 연결 내에서 BEGIN TRANSACTION 문과 COMMIT 문 사이의 모든 것은 같은 트랜잭션에 속하는 것으로 여겨진다.
반면, 비관계형 데이터베이스는 이런 식으로 연산을 묶는 방법이 없는 경우가 많다.
-> 어떤 키에 대한 연산은 성공하고 나머지 키에 대한 연산은 실패해서 데이터베이스가 부분적으로 갱신된 상태가 될 수 있다.

#### 단일 객체 쓰기

단일 객체 수준에서 원자성과 격리성을 제공하는 것을 목표
원자성은 장애 복구용 로그를 써서 구현할 수 있고, 격리성은 각 객체에 잠금을 사용해 구현할 수 있다.
데이터베이스의 증가 연산 : 더 복잡한 원자적 연산
compare-and-set은 변경하려는 값이 누군가에 의해 동시에 바뀌지 않았을 때만 쓰기가 반영되도록 허용한다.
단일 객체 연산은 여러 클라이언트에서 동시에 같은 객체에 쓰려고 할 때 갱신 손실을 방지하므로 유용하다.
하지만, 일반적으로 쓰이는 의미의 트랜잭션은 아니다.
트랜잭션은 보통 다중 객체에 대한 다중 연산을 하나의 실행 단위로 묶는 매커니즘으로 이해된다.

#### 다중 객체 트랜잭션의 필요성

많은 분산 데이터스토어는 다중 객체 트랜잭션 지원을 포기
-> 여러 파티션에 걸쳐서 구현하기 어렵고 매우 높은 가용성과 성능이 필요한 곳에서는 방해가 되는 시나리오도 존재.

#### 오류와 어보트 처리

트랜잭셤의 핵심 기능 : 오류 발생 -> 어보트되고 안전학 ㅔ재시도 가능
ACID 데이터베이스는 이 철학을 바탕으로 함
하지만, 모든 시스템이 이 철학을 따르지는 않음
-> 리더 없는 복제를 사용하는 데이터스토어 : 최선을 다하는 원칙을 기반으로 훨씬 더 많은 일을 함
: 데이터베이스는 가능한 모든 것을 할 것이며 그 때문에 오류가 발생하면 이미 한 일은 취소하지 않는다.
-> 오류 복구는 애플리케이션에게 책임이 있다.

오류는 필연적으로 발생하지만 많은 소프트웨어 개발자들은 오류 처리의 복잡한 내용은 신경쓰지 않고 낙관적인 상황만 생각하려고 한다.
인기있는 객체 관계형 매핑 프레임워크들은 어보트된 트랜잭션을 재시도하지 않는다.
어보트의 취지는 안전하게 재시도를 할 수 있게 하는데 있다.
하지만, 어보트된 트랜잭션을 재시도하는 것은 간단하고 효과적인 오류 처리 매커니즘이지만 완벽하지는 않다.

- 중복 발생 가능
- 과부화로 인한 오류 발생이라면 상황을 악화
- 영구적인 오류는 재시도해도 소용이 없음
  등등

## 완화된 격리 수준

동시성 문제 : 트랜잭션이 다른 트랜잭션에서 동시에 변경한 데이터를 읽거나 두 트랜잭션이 동시에 같은 데이터를 변경하려고 할 때만 나타난다.
데이터베이스는 오랫동안 트랜잭션 격리를 제공함
-> 애플리케이션 개발자들에게 동시성 문제를 감추려고 했다.
직렬성 격리 : 데이터베이스가 여러 트랜잭션들이 직렬적으로 실행되는 것과 동일한 결과가 나오도록 보장한다는 것을 의미
하지만, 성능 비용이 있고 많은 데이터베이스들은 그 비용을 지불하려고 하지 않는다.
-> 완화된 격리 수준을 사용하는 시스템들이 흔하다.

### 커밋 후 읽기

가장 기본적인 수준의 트랜잭션 격리 : Read Committed

1. 데이터베이스에서 읽을 때 커밋된 데이터만 보게 된다 (No Dirty Read)
2. 데이터베이스에 쓸 때 커밋된 데이터만 덮어쓰게 된다 (No Dirty Write)

#### 더티 읽기 방지

더티 읽기 : 다른 트랜잭션에서 커밋되지 않은 데이터를 볼 수 있는 것

Read Committed에서는 더티 읽기를 막아야 함
더티 읽기는 막는 게 유용한 이유

- 트랜잭션이 여러 객체를 갱신하는데 더티 읽기가 발생 -> 다른 트랜잭션이 일부는 갱신된 값을, 일부는 갱신되지 않은 값을 볼 수 있다.
- 트랜잭션이 어보트되면 그 때까지 쓴 내용은 모두 롤백 -> 실제로는 데이터베이스에 결코 커밋되지 않을 데이터를 볼 수 있다.

#### 더티 쓰기 방지

더티 쓰기 : 먼저 쓴 내용이 아직 커밋되지 않은 트랜잭션에서 쓴 것이고 나중에 실행된 쓰기 작업이 커밋되지 않은 값을 덮어써버리는 것

Read Committed에서는 더티 쓰기를 막아야 함
보통 먼저 쓴 트랜잭션이 커밋되거나 어보트될 때까지 두 번째 쓰기는 지연시키는 방법을 사용

#### 커밋 후 읽기 구현

가장 흔한 방법 : 로우 수준 잠금 사용 -> 더티 쓰기 방지
트랜잭션에서 특정 객체를 변경하고 싶다면 먼저 해당 객체에 대한 잠금을 획득해야 한다.
트랜잭션이 커밋되거나 어보트될 때까지 잠금을 보유하고 있어야 한다.
쓰여진 모든 객체에 대해 데이터베이스는 과거에 커밋된 값과 현재 쓰기 잠금을 갖고 있는 트랜잭션에서 쓴 새로운 값을 모두 기억한다.
해당 트랜잭션이 실행 중인 동안 그 객체를 읽는 다른 트랜잭션들은 과거의 값을 읽게 된다.
새 값이 커밋되어야함 다른 트랜잭션들이 새 값을 읽을 수 있게 된다.

### 스냅숏 격리와 반복 읽기

커밋 후 읽기 격리는 피상적으로 보면 트랜잭션이 해야 하는 모든 일을 해 주는 것으로 생각해도 무리가 아니다

1. 어보트를 허용하고,
2. 트랜잭션의 미완료된 결과를 읽는 것을 방지하고,
3. 동시에 실행되는 쓰기가 섞이는 것을 막아준다.

하지만, 커밋 후 읽기 격리 수준을 사용하더라도 동시성 버그가 생길 수 있는 경우가 아직 많이 존재.
-> NonRepeatable Read (비반복 읽기) 나 읽기 스큐(Read Skew)
: 조회 시 이전 질의에서 봤던 것과 다른 값을 보게 되는 현상
위 현상은 커밋 후 읽기 격리에서는 받아들일 수 있는 것으로 여겨진다.
또한, 지속적인 문제는 아니다.

스냅숏 격리는 이런 문제의 가장 흔한 해결책이다.

- 각 트랜잭션은 데이터베이스의 일관된 스냅숏으로부터 읽는다.
  -> 트랜잭션은 시작할 때 데이터베이스에 커밋된 상태였던 모든 데이터를 본다.
- 데이터가 나중에 다른 트랜잭션에 의해 바뀌더라도 각 트랜잭션은 특정한 시점의 과거 데이터를 볼 뿐이다.
- 백업이나 분석처럼 실행하는 데 오래 걸리며 읽기만 실행하는 질의에 요긴함

: 트랜잭션이 특정 시점에 고정된 데이터베이스의 일관된 스냅숏만 볼 수 있다고 이해하면 편함

#### 스냅숏 격리 구현

스냅숏 격리 구현은 커밋 후 읽기 격리처럼 전형적으로 더티 쓰기를 방지하기 위해 쓰기 잠금을 사용한다.
하지만, 읽을 때는 아무 잠금도 필요 없다.

스냅숏 격리의 핵심 원리
: 읽는 쪽에서 쓰는 쪽을 결코 차단하지 않고 쓰는 쪽에서 읽는 쪽을 결코 차단하지 않는다.

데이터베이스는 객체마다 커밋된 버전 여러 개를 유지
-> 진행 중인 여러 트랜잭션에서 서로 다른 시점의 데이터베이스 상태를 봐야할 수도 있기 때문
-> 다중 버전 동시성 제어 (MVCC, Multi-Version Concurrency Control)

데이터베이스가 스냅숏 격리가 아니라 커밋 후 읽기 격리만 제공할 필요가 있다면 객체마다 버전 2개씩만 유지하면 된다.
-> 커밋된 버전과 덮어 쓰여졌지만 아직 커밋되지 않은 버전

- 커밋 후 읽기 : 질의마다 독립된 스냅숏을 사용
- 스냅숏 격리 : 전체 트랜잭션에 대해 동일한 스냅숏을 사용

MVCC 기반 스냅숏 격리 구현

- 트랜잭션이 시작하면 계속 증가하는 고유한 트랜잭션 ID를 할당받는다.
- 테이블의 각 로우에는 그 로우를 테이블에 삽입한 트랜잭션의 ID를 갖는 created_by 필드
- 각 로우에는 처음에는 비어있는 deleted_by 필드 : 트랜잭션이 로우를 삭제하면 실제로 데이터베이스에서 지우지 않고 deleted_by 필드를 삭제 요청 트랜잭션의 ID로 설정함으로써 지워졌다고 표시
- 나중에 아무 트랜잭션도 더 이상 삭제된 데이터에 접근하지 않는게 확실 -> 데이터베이스의 가비지 컬렉션 프로세스가 지워졌다고 표시된 로우들을 삭제하여 사용량 줄임

#### 일관된 스냅숏을 보는 가시성 규칙

트랜잭션은 데이터베이스에서 객체를 읽을 때 트랜잭션 ID를 사용해 어떤 것을 볼 수 있고 어떤 것을 볼 수 없는지를 결정.

1. 각 트랜잭션을 시작할 때 그 시점에 진행 중인 모든 트랜잭션의 목록을 만든다.
   -> 이 트랜잭션이 쓴 데이터는 무시된다.
2. 어보트된 트랜잭션이 쓴 데이터는 모두 무시된다.
3. 트랜잭션 ID가 더 큰 트랜잭션이 쓴 데이터는 모두 무시된다.
4. 그 밖의 모든 데이터는 애플리케이션의 질의로 볼 수 있다.

바꿔말하면, 아래 두 조건이 모두 참이면 객체를 볼 수 있다.

- 읽기를 실행하는 트랜잭션이 시작하는 시점에 읽기 대상 객체를 생성한 트랜잭션이 이미 커밋된 상태
- 읽기 대상 객체가 삭제된 것으로 표시되지 않았다. 또는 삭제된 것으로 표시됐지만 읽기를 실행한 트랜잭션이 시작한 시점에 삭제 요청 트랜잭션이 아직 커밋되지 않았다.

데이터베이스는 갱신할 때 값을 교체 X -> 새 버전을 생성 -> 작은 오버헤드만 유발 & 일관된 스냅숏 제공

#### 색인과 스냅숏 격리

MVCC 데이터베이스에서 색인 동작 방식
하나의 선택지 : 단순하게 색인이 객체의 모든 버전을 가리키게 하고 색인 질의가 현재 트랜잭션에서 볼 수 없는 버전을 걸러내게 하는 것
가비지 컬렉션이 어떤 트랜잭션에게도 더 이상 보이지 않는 오래된 객체 버전을 삭제할 때 대응되는 색인 항목도 삭제

#### 반복 읽기와 혼란스러운 이름

스냅숏 격리는 유용한 격리 수준이며 특히 읽기 전용 트랜잭션에 유용
Oracle에서는 직렬성, MySQL에서는 Repeatable Read라 칭함

이름이 혼란스러운 이유 : SQL 표준에 스냅숏 격리의 개념이 없기 때문

### 갱신 손실 방지

갱신 손실(Lost update) : 동시에 실행되는 쓰기 트랜잭션 사이에 발생할 수 있는 흥미로운 종류의 충돌 중 1가지

- 애플리케이션이 데이터베이스에서 값을 읽고 변경한 후 변경된 값을 다시 쓸 때 발생
- 만약 두 트랜잭션이 이 작업을 동시에 하면 두 번째 쓰기 작업이 첫 번째 변경을 포함하지 않으므로 변경 중 하나는 손실 가능

#### 원자적 쓰기 연산

원자적 갱신 연산 : 애플리케이션 코드에서 read-modify-write 주기를 구현할 필요를 없애줌
`UPDATE counters SET value = value + 1 WHERE key = 'foo';`
: 대부분의 관계형 데이터베이스에서 동시성 안전한 명령어

원자적 연산은 객체를 읽을 때 그 객체에 독점적인 잠금을 획득해서 구현한다.
갱신이 적용될 때까지 다른 트랜잭션에서 그 객체를 읽지 못한다.
-> 커서 안정성
다른 선택지 : 모든 원자적 연산을 단일 스레드에서 실행되도록 강제하는 것

주의. 객체 관계형 매핑 프레임워크를 사용하면 뜻하지 않게 데이터베이스가 제공하는 원자적 연산을 사용하는 대신 불안전한 read-modify-write 주기를 실행하는 코드를 작성하기 쉽다.

#### 명시적인 잠금

데이터베이스에 내장된 원자적 연산이 필요한 기능을 제공하지 않을 때 갱신 손실을 막는 또 다른 선택지
: 애플리케이션에서 갱신할 객체를 명시적으로 잠그는 것
-> 애플리케이션이 read-modify-write 주기를 수행할 수 있고, 다른 트랜잭션이 동시에 같은 객체를 읽으려 하면 첫 번째 주기가 완료될 때까지 기다리도록 강제됨

`SELECT * FROM figures WHERE name = 'robot' AND game_id = 222 FOR UPDATE`
FOR UPDATE : 데이터베이스가 이 질의에 의해 반환된 모든 로우에 잠금을 획득해야 함

### 갱신 손실 자동 감지

원자적 연산과 잠금은 read-modify-write 주기가 순차적으로 실행되도록 강제 -> 갱신 손실을 방지하는 방법
대안 : 병렬 실행을 허용, 트랜잭션 고나리자가 갱신 손실을 발견하면 트랜잭션을 어보트시키고 read-modify-write 주기를 재시도하도록 강제하는 방법
대안의 이점 : 데이터베이스가 이 확인을 스냅숏 격리와 결합해 효율적으로 수행할 수 있음
실제로, PostgreSQL의 반복 읽기, Oracle의 직렬성, SQL Server의 스냅숏 격리 수준은 갱신 손실이 발생하면 자동으로 발견해서 문제가 되는 트랜잭션을 어보트시킨다.
하지만, MySQL의 반복 읽기는 갱신 손실을 감지하지 않는다.

#### Compare-and-set

트랜잭션을 제공하지 않는 데이터베이스 중에는 원자적 Compare-and-set 연산을 제공하는 것도 존재.
이 연산의 목적 : 값을 마지막으로 읽은 후로 변경되지 않았을 때만 갱신을 허용 -> 갱신 손실 회피
현재 값이 이전에 읽은 값과 일치하지 않으면 갱신은 반영되지 않음
-> read-modify-write 주기를 재시도해야 함

### 충돌 해소와 복제

복제가 적용된 데이터베이스에서 갱신 손실을 막는 것은 다른 차원의 문제
데이터가 다른 노드들에서 동시에 변경될 수 있음 -> 갱신 손실 방지를 위해서는 추가 단계 필요
잠금과 compare-and-set 연산은 데이터의 최신 복사본이 하나만 있다고 가정한다.
다중 리더 또는 리더 없는 복제를 사용하는 데이터베이스는

1. 여러 쓰기가 동시에 실행
2. 비동기식으로 복제되는 것을 허용
   -> 데이터의 최신 복사본이 하나만 있으리라고 보장할 수 없음
   -> 잠금과 compare-and-set을 기반으로 한 기법을 적용할 수 없음

복제가 적용된 데이터베이스에서 흔히 쓰는 방법

1. 쓰기가 동시에 실행될 때
2. 한 값에 대해 여러 개의 충돌된 버전(형제, Sibling)을 생성하는 것을 허용
3. 차후에 애플리케이션 코드나 특별한 데이터 구조를 사용해 충돌을 해소
4. 이 버전들을 병합

원자적 연산은 복제 상황에서도 잘 동작한다.
